Training architectures/transformer.sh model with config file config_files/transformer/7.config and data version ../format_delex/BPE_1_000 ...
Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer_iwslt_de_en', attention_dropout=0.0, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=True, curriculum=0, data='../format_delex/BPE_1_000', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=256, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=256, decoder_layerdrop=0, decoder_layers=3, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=256, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.2, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=256, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=3, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format='json', log_interval=1000, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=20, max_sentences=16, max_sentences_valid=16, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/transformer/v0/che', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='triple', target_lang='lex', task='translation', tensorboard_logdir='checkpoints/transformer/v0/log', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0)
| [triple] dictionary: 1000 types
| [lex] dictionary: 1000 types
| loaded 4313 examples from: ../format_delex/BPE_1_000/valid.triple-lex.triple
| loaded 4313 examples from: ../format_delex/BPE_1_000/valid.triple-lex.lex
| ../format_delex/BPE_1_000 valid triple-lex 4313 examples
TransformerModel(
  (encoder): TransformerEncoder(
    (embed_tokens): Embedding(1000, 256, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 256, padding_idx=1)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 256, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 256, padding_idx=1)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
)
| model transformer_iwslt_de_en, criterion LabelSmoothedCrossEntropyCriterion
| num. model params: 6310912 (num. trained: 6310912)
| training on 1 GPUs
| max tokens per GPU = None and max sentences per GPU = 16
| no existing checkpoint found checkpoints/transformer/v0/che/checkpoint_last.pt
| loading train data for epoch 0
| loaded 34338 examples from: ../format_delex/BPE_1_000/train.triple-lex.triple
| loaded 34338 examples from: ../format_delex/BPE_1_000/train.triple-lex.lex
| ../format_delex/BPE_1_000 train triple-lex 34338 examples
| NOTICE: your device may support faster training with --fp16
{"epoch": 1, "update": 0.466, "loss": "7.607", "nll_loss": "7.179", "ppl": "144.86", "wps": "5570", "ups": "10", "wpb": "577.300", "bsz": "15.986", "num_updates": "1001", "lr": "0.000250325", "gnorm": "2.126", "clip": "0.000", "oom": "0.000", "wall": "105", "train_wall": "98"}
{"epoch": 1, "update": 0.932, "loss": "6.441", "nll_loss": "5.810", "ppl": "56.12", "wps": "5372", "ups": "10", "wpb": "564.835", "bsz": "15.993", "num_updates": "2001", "lr": "0.0005003", "gnorm": "2.052", "clip": "0.000", "oom": "0.000", "wall": "212", "train_wall": "198"}
{"epoch": 1, "train_loss": "6.321", "train_nll_loss": "5.669", "train_ppl": "50.88", "train_wps": "5394", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "2147", "train_lr": "0.000536796", "train_gnorm": "2.033", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "227", "train_train_wall": "213"}
{"epoch": 1, "valid_loss": "4.493", "valid_nll_loss": "3.426", "valid_ppl": "10.75", "valid_num_updates": "2147"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 1 @ 2147 updates) (writing took 0.2543454170227051 seconds)
{"epoch": 2, "update": 1.466, "loss": "4.413", "nll_loss": "3.410", "ppl": "10.63", "wps": "5264", "ups": "9", "wpb": "560.421", "bsz": "15.986", "num_updates": "3148", "lr": "0.000787021", "gnorm": "1.711", "clip": "0.000", "oom": "0.000", "wall": "341", "train_wall": "313"}
{"epoch": 2, "update": 1.932, "loss": "4.273", "nll_loss": "3.245", "ppl": "9.48", "wps": "5312", "ups": "9", "wpb": "565.425", "bsz": "15.993", "num_updates": "4148", "lr": "0.000981998", "gnorm": "1.639", "clip": "0.000", "oom": "0.000", "wall": "448", "train_wall": "413"}
{"epoch": 2, "train_loss": "4.254", "train_nll_loss": "3.224", "train_ppl": "9.34", "train_wps": "5343", "train_ups": "9", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "4294", "train_lr": "0.000965159", "train_gnorm": "1.627", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "463", "train_train_wall": "427"}
{"epoch": 2, "valid_loss": "3.732", "valid_nll_loss": "2.522", "valid_ppl": "5.74", "valid_num_updates": "4294", "valid_best_loss": "3.73226"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 2 @ 4294 updates) (writing took 0.3119487762451172 seconds)
{"epoch": 3, "update": 2.466, "loss": "3.780", "nll_loss": "2.678", "ppl": "6.4", "wps": "5273", "ups": "9", "wpb": "564.119", "bsz": "15.986", "num_updates": "5295", "lr": "0.000869155", "gnorm": "1.419", "clip": "0.000", "oom": "0.000", "wall": "577", "train_wall": "528"}
{"epoch": 3, "update": 2.932, "loss": "3.689", "nll_loss": "2.575", "ppl": "5.96", "wps": "5301", "ups": "9", "wpb": "566.214", "bsz": "15.993", "num_updates": "6295", "lr": "0.000797135", "gnorm": "1.372", "clip": "0.000", "oom": "0.000", "wall": "684", "train_wall": "628"}
{"epoch": 3, "train_loss": "3.679", "train_nll_loss": "2.564", "train_ppl": "5.91", "train_wps": "5311", "train_ups": "9", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "6441", "train_lr": "0.000788049", "train_gnorm": "1.367", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "700", "train_train_wall": "643"}
{"epoch": 3, "valid_loss": "3.364", "valid_nll_loss": "2.085", "valid_ppl": "4.24", "valid_num_updates": "6441", "valid_best_loss": "3.36354"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 3 @ 6441 updates) (writing took 0.3325366973876953 seconds)
{"epoch": 4, "update": 3.466, "loss": "3.401", "nll_loss": "2.249", "ppl": "4.75", "wps": "5456", "ups": "9", "wpb": "579.127", "bsz": "15.986", "num_updates": "7442", "lr": "0.000733137", "gnorm": "1.260", "clip": "0.000", "oom": "0.000", "wall": "813", "train_wall": "743"}
{"epoch": 4, "update": 3.932, "loss": "3.347", "nll_loss": "2.188", "ppl": "4.56", "wps": "5376", "ups": "9", "wpb": "571.589", "bsz": "15.993", "num_updates": "8442", "lr": "0.000688347", "gnorm": "1.246", "clip": "0.000", "oom": "0.000", "wall": "920", "train_wall": "843"}
{"epoch": 4, "train_loss": "3.340", "train_nll_loss": "2.180", "train_ppl": "4.53", "train_wps": "5336", "train_ups": "9", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "8588", "train_lr": "0.000682471", "train_gnorm": "1.247", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "935", "train_train_wall": "858"}
{"epoch": 4, "valid_loss": "3.163", "valid_nll_loss": "1.853", "valid_ppl": "3.61", "valid_num_updates": "8588", "valid_best_loss": "3.16286"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 4 @ 8588 updates) (writing took 0.3433725833892822 seconds)
{"epoch": 5, "update": 4.466, "loss": "3.182", "nll_loss": "2.002", "ppl": "4", "wps": "5394", "ups": "9", "wpb": "569.368", "bsz": "16.000", "num_updates": "9589", "lr": "0.000645867", "gnorm": "1.195", "clip": "0.000", "oom": "0.000", "wall": "1049", "train_wall": "957"}
{"epoch": 5, "update": 4.932, "loss": "3.158", "nll_loss": "1.975", "ppl": "3.93", "wps": "5311", "ups": "9", "wpb": "563.837", "bsz": "15.993", "num_updates": "10589", "lr": "0.000614614", "gnorm": "1.190", "clip": "0.000", "oom": "0.000", "wall": "1155", "train_wall": "1058"}
{"epoch": 5, "train_loss": "3.155", "train_nll_loss": "1.972", "train_ppl": "3.92", "train_wps": "5349", "train_ups": "9", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "10735", "train_lr": "0.00061042", "train_gnorm": "1.187", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1171", "train_train_wall": "1072"}
{"epoch": 5, "valid_loss": "3.027", "valid_nll_loss": "1.687", "valid_ppl": "3.22", "valid_num_updates": "10735", "valid_best_loss": "3.02714"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 5 @ 10735 updates) (writing took 0.31069064140319824 seconds)
{"epoch": 6, "update": 5.466, "loss": "3.036", "nll_loss": "1.837", "ppl": "3.57", "wps": "5229", "ups": "9", "wpb": "558.641", "bsz": "15.986", "num_updates": "11736", "lr": "0.000583808", "gnorm": "1.154", "clip": "0.000", "oom": "0.000", "wall": "1285", "train_wall": "1173"}
{"epoch": 6, "update": 5.932, "loss": "3.029", "nll_loss": "1.830", "ppl": "3.55", "wps": "5382", "ups": "9", "wpb": "568.835", "bsz": "15.993", "num_updates": "12736", "lr": "0.00056042", "gnorm": "1.147", "clip": "0.000", "oom": "0.000", "wall": "1390", "train_wall": "1271"}
{"epoch": 6, "train_loss": "3.027", "train_nll_loss": "1.828", "train_ppl": "3.55", "train_wps": "5387", "train_ups": "9", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "12882", "train_lr": "0.000557235", "train_gnorm": "1.147", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1404", "train_train_wall": "1285"}
{"epoch": 6, "valid_loss": "2.950", "valid_nll_loss": "1.604", "valid_ppl": "3.04", "valid_num_updates": "12882", "valid_best_loss": "2.94966"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 6 @ 12882 updates) (writing took 0.33644771575927734 seconds)
{"epoch": 7, "update": 6.466, "loss": "2.936", "nll_loss": "1.723", "ppl": "3.3", "wps": "5471", "ups": "10", "wpb": "574.266", "bsz": "16.000", "num_updates": "13883", "lr": "0.00053677", "gnorm": "1.123", "clip": "0.000", "oom": "0.000", "wall": "1516", "train_wall": "1383"}
{"epoch": 7, "update": 6.932, "loss": "2.937", "nll_loss": "1.727", "ppl": "3.31", "wps": "5443", "ups": "10", "wpb": "568.710", "bsz": "15.993", "num_updates": "14883", "lr": "0.000518424", "gnorm": "1.121", "clip": "0.000", "oom": "0.000", "wall": "1620", "train_wall": "1481"}
{"epoch": 7, "train_loss": "2.935", "train_nll_loss": "1.725", "train_ppl": "3.31", "train_wps": "5445", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "15029", "train_lr": "0.000515899", "train_gnorm": "1.120", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1635", "train_train_wall": "1495"}
{"epoch": 7, "valid_loss": "2.879", "valid_nll_loss": "1.520", "valid_ppl": "2.87", "valid_num_updates": "15029", "valid_best_loss": "2.87908"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 7 @ 15029 updates) (writing took 0.3287618160247803 seconds)
{"epoch": 8, "update": 7.466, "loss": "2.870", "nll_loss": "1.651", "ppl": "3.14", "wps": "5461", "ups": "10", "wpb": "572.825", "bsz": "15.986", "num_updates": "16030", "lr": "0.000499532", "gnorm": "1.096", "clip": "0.000", "oom": "0.000", "wall": "1747", "train_wall": "1594"}
{"epoch": 8, "update": 7.932, "loss": "2.867", "nll_loss": "1.649", "ppl": "3.14", "wps": "5440", "ups": "10", "wpb": "568.309", "bsz": "15.993", "num_updates": "17030", "lr": "0.000484644", "gnorm": "1.103", "clip": "0.000", "oom": "0.000", "wall": "1851", "train_wall": "1692"}
{"epoch": 8, "train_loss": "2.866", "train_nll_loss": "1.648", "train_ppl": "3.13", "train_wps": "5442", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "17176", "train_lr": "0.00048258", "train_gnorm": "1.102", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1866", "train_train_wall": "1706"}
{"epoch": 8, "valid_loss": "2.844", "valid_nll_loss": "1.471", "valid_ppl": "2.77", "valid_num_updates": "17176", "valid_best_loss": "2.84422"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 8 @ 17176 updates) (writing took 0.37769317626953125 seconds)
{"epoch": 9, "update": 8.466, "loss": "2.809", "nll_loss": "1.583", "ppl": "3", "wps": "5582", "ups": "10", "wpb": "574.617", "bsz": "16.000", "num_updates": "18177", "lr": "0.000469104", "gnorm": "1.085", "clip": "0.000", "oom": "0.000", "wall": "1975", "train_wall": "1802"}
{"epoch": 9, "update": 8.932, "loss": "2.813", "nll_loss": "1.588", "ppl": "3.01", "wps": "5472", "ups": "10", "wpb": "569.870", "bsz": "15.993", "num_updates": "19177", "lr": "0.000456709", "gnorm": "1.089", "clip": "0.000", "oom": "0.000", "wall": "2081", "train_wall": "1901"}
{"epoch": 9, "train_loss": "2.811", "train_nll_loss": "1.586", "train_ppl": "3", "train_wps": "5445", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "19323", "train_lr": "0.00045498", "train_gnorm": "1.089", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2096", "train_train_wall": "1916"}
{"epoch": 9, "valid_loss": "2.803", "valid_nll_loss": "1.436", "valid_ppl": "2.71", "valid_num_updates": "19323", "valid_best_loss": "2.8032"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 9 @ 19323 updates) (writing took 0.37691235542297363 seconds)
{"epoch": 10, "update": 9.466, "loss": "2.764", "nll_loss": "1.533", "ppl": "2.89", "wps": "5490", "ups": "10", "wpb": "569.101", "bsz": "16.000", "num_updates": "20324", "lr": "0.000443635", "gnorm": "1.080", "clip": "0.000", "oom": "0.000", "wall": "2207", "train_wall": "2013"}
{"epoch": 10, "update": 9.932, "loss": "2.765", "nll_loss": "1.535", "ppl": "2.9", "wps": "5464", "ups": "10", "wpb": "569.656", "bsz": "16.000", "num_updates": "21324", "lr": "0.000433107", "gnorm": "1.078", "clip": "0.000", "oom": "0.000", "wall": "2312", "train_wall": "2112"}
{"epoch": 10, "train_loss": "2.765", "train_nll_loss": "1.534", "train_ppl": "2.9", "train_wps": "5447", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "21470", "train_lr": "0.000431632", "train_gnorm": "1.078", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2327", "train_train_wall": "2126"}
{"epoch": 10, "valid_loss": "2.780", "valid_nll_loss": "1.404", "valid_ppl": "2.65", "valid_num_updates": "21470", "valid_best_loss": "2.77995"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 10 @ 21470 updates) (writing took 0.3136568069458008 seconds)
{"epoch": 11, "update": 10.466, "loss": "2.711", "nll_loss": "1.473", "ppl": "2.78", "wps": "5350", "ups": "10", "wpb": "553.376", "bsz": "15.986", "num_updates": "22471", "lr": "0.000421909", "gnorm": "1.061", "clip": "0.000", "oom": "0.000", "wall": "2438", "train_wall": "2224"}
{"epoch": 11, "update": 10.932, "loss": "2.727", "nll_loss": "1.493", "ppl": "2.81", "wps": "5558", "ups": "10", "wpb": "569.901", "bsz": "15.993", "num_updates": "23471", "lr": "0.000412823", "gnorm": "1.067", "clip": "0.000", "oom": "0.000", "wall": "2539", "train_wall": "2319"}
{"epoch": 11, "train_loss": "2.726", "train_nll_loss": "1.491", "train_ppl": "2.81", "train_wps": "5539", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "23617", "train_lr": "0.000411545", "train_gnorm": "1.068", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2554", "train_train_wall": "2333"}
{"epoch": 11, "valid_loss": "2.746", "valid_nll_loss": "1.369", "valid_ppl": "2.58", "valid_num_updates": "23617", "valid_best_loss": "2.74584"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 11 @ 23617 updates) (writing took 0.34052515029907227 seconds)
{"epoch": 12, "update": 11.466, "loss": "2.686", "nll_loss": "1.446", "ppl": "2.72", "wps": "5670", "ups": "10", "wpb": "577.828", "bsz": "16.000", "num_updates": "24618", "lr": "0.000403091", "gnorm": "1.051", "clip": "0.000", "oom": "0.000", "wall": "2663", "train_wall": "2429"}
{"epoch": 12, "update": 11.932, "loss": "2.689", "nll_loss": "1.450", "ppl": "2.73", "wps": "5572", "ups": "10", "wpb": "567.203", "bsz": "15.993", "num_updates": "25618", "lr": "0.000395146", "gnorm": "1.064", "clip": "0.000", "oom": "0.000", "wall": "2765", "train_wall": "2524"}
{"epoch": 12, "train_loss": "2.691", "train_nll_loss": "1.452", "train_ppl": "2.74", "train_wps": "5570", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "25764", "train_lr": "0.000394025", "train_gnorm": "1.064", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2780", "train_train_wall": "2539"}
{"epoch": 12, "valid_loss": "2.733", "valid_nll_loss": "1.348", "valid_ppl": "2.55", "valid_num_updates": "25764", "valid_best_loss": "2.73268"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 12 @ 25764 updates) (writing took 0.368560791015625 seconds)
{"epoch": 13, "update": 12.466, "loss": "2.655", "nll_loss": "1.413", "ppl": "2.66", "wps": "5573", "ups": "10", "wpb": "568.865", "bsz": "15.986", "num_updates": "26765", "lr": "0.000386586", "gnorm": "1.053", "clip": "0.000", "oom": "0.000", "wall": "2889", "train_wall": "2635"}
{"epoch": 13, "update": 12.932, "loss": "2.661", "nll_loss": "1.419", "ppl": "2.67", "wps": "5569", "ups": "10", "wpb": "566.928", "bsz": "15.993", "num_updates": "27765", "lr": "0.000379561", "gnorm": "1.055", "clip": "0.000", "oom": "0.000", "wall": "2990", "train_wall": "2730"}
{"epoch": 13, "train_loss": "2.662", "train_nll_loss": "1.421", "train_ppl": "2.68", "train_wps": "5575", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "27911", "train_lr": "0.000378567", "train_gnorm": "1.056", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3005", "train_train_wall": "2744"}
{"epoch": 13, "valid_loss": "2.705", "valid_nll_loss": "1.314", "valid_ppl": "2.49", "valid_num_updates": "27911", "valid_best_loss": "2.70472"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 13 @ 27911 updates) (writing took 0.3297882080078125 seconds)
{"epoch": 14, "update": 13.466, "loss": "2.627", "nll_loss": "1.381", "ppl": "2.6", "wps": "5571", "ups": "10", "wpb": "566.256", "bsz": "16.000", "num_updates": "28912", "lr": "0.000371955", "gnorm": "1.052", "clip": "0.000", "oom": "0.000", "wall": "3114", "train_wall": "2839"}
{"epoch": 14, "update": 13.932, "loss": "2.637", "nll_loss": "1.392", "ppl": "2.62", "wps": "5586", "ups": "10", "wpb": "569.595", "bsz": "15.993", "num_updates": "29912", "lr": "0.000365685", "gnorm": "1.054", "clip": "0.000", "oom": "0.000", "wall": "3216", "train_wall": "2935"}
{"epoch": 14, "train_loss": "2.637", "train_nll_loss": "1.392", "train_ppl": "2.62", "train_wps": "5570", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "30058", "train_lr": "0.000364796", "train_gnorm": "1.054", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3231", "train_train_wall": "2949"}
{"epoch": 14, "valid_loss": "2.687", "valid_nll_loss": "1.300", "valid_ppl": "2.46", "valid_num_updates": "30058", "valid_best_loss": "2.68687"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 14 @ 30058 updates) (writing took 0.342343807220459 seconds)
{"epoch": 15, "update": 14.466, "loss": "2.607", "nll_loss": "1.359", "ppl": "2.57", "wps": "5665", "ups": "10", "wpb": "574.982", "bsz": "15.986", "num_updates": "31059", "lr": "0.000358869", "gnorm": "1.044", "clip": "0.000", "oom": "0.000", "wall": "3339", "train_wall": "3045"}
{"epoch": 15, "update": 14.932, "loss": "2.615", "nll_loss": "1.368", "ppl": "2.58", "wps": "5614", "ups": "10", "wpb": "571.160", "bsz": "15.993", "num_updates": "32059", "lr": "0.000353228", "gnorm": "1.053", "clip": "0.000", "oom": "0.000", "wall": "3441", "train_wall": "3140"}
{"epoch": 15, "train_loss": "2.614", "train_nll_loss": "1.368", "train_ppl": "2.58", "train_wps": "5578", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "32205", "train_lr": "0.000352426", "train_gnorm": "1.055", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3456", "train_train_wall": "3154"}
{"epoch": 15, "valid_loss": "2.696", "valid_nll_loss": "1.303", "valid_ppl": "2.47", "valid_num_updates": "32205", "valid_best_loss": "2.68687"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_last.pt (epoch 15 @ 32205 updates) (writing took 0.2007596492767334 seconds)
{"epoch": 16, "update": 15.466, "loss": "2.576", "nll_loss": "1.325", "ppl": "2.51", "wps": "5417", "ups": "10", "wpb": "551.835", "bsz": "16.000", "num_updates": "33206", "lr": "0.000347074", "gnorm": "1.053", "clip": "0.000", "oom": "0.000", "wall": "3564", "train_wall": "3250"}
{"epoch": 16, "update": 15.932, "loss": "2.591", "nll_loss": "1.343", "ppl": "2.54", "wps": "5560", "ups": "10", "wpb": "566.442", "bsz": "15.993", "num_updates": "34206", "lr": "0.000341963", "gnorm": "1.051", "clip": "0.000", "oom": "0.000", "wall": "3666", "train_wall": "3346"}
{"epoch": 16, "train_loss": "2.593", "train_nll_loss": "1.344", "train_ppl": "2.54", "train_wps": "5568", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "34352", "train_lr": "0.000341235", "train_gnorm": "1.051", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3681", "train_train_wall": "3360"}
{"epoch": 16, "valid_loss": "2.664", "valid_nll_loss": "1.267", "valid_ppl": "2.41", "valid_num_updates": "34352", "valid_best_loss": "2.66447"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 16 @ 34352 updates) (writing took 0.3331735134124756 seconds)
{"epoch": 17, "update": 16.466, "loss": "2.574", "nll_loss": "1.323", "ppl": "2.5", "wps": "5550", "ups": "10", "wpb": "567.820", "bsz": "16.000", "num_updates": "35353", "lr": "0.00033637", "gnorm": "1.045", "clip": "0.000", "oom": "0.000", "wall": "3790", "train_wall": "3456"}
{"epoch": 17, "update": 16.932, "loss": "2.575", "nll_loss": "1.324", "ppl": "2.5", "wps": "5567", "ups": "10", "wpb": "568.294", "bsz": "16.000", "num_updates": "36353", "lr": "0.000331711", "gnorm": "1.050", "clip": "0.000", "oom": "0.000", "wall": "3892", "train_wall": "3552"}
{"epoch": 17, "train_loss": "2.574", "train_nll_loss": "1.323", "train_ppl": "2.5", "train_wps": "5560", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "36499", "train_lr": "0.000331047", "train_gnorm": "1.051", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3907", "train_train_wall": "3566"}
{"epoch": 17, "valid_loss": "2.654", "valid_nll_loss": "1.263", "valid_ppl": "2.4", "valid_num_updates": "36499", "valid_best_loss": "2.65382"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 17 @ 36499 updates) (writing took 0.33116722106933594 seconds)
{"epoch": 18, "update": 17.466, "loss": "2.548", "nll_loss": "1.293", "ppl": "2.45", "wps": "5644", "ups": "10", "wpb": "576.940", "bsz": "15.986", "num_updates": "37500", "lr": "0.000326599", "gnorm": "1.038", "clip": "0.000", "oom": "0.000", "wall": "4016", "train_wall": "3662"}
{"epoch": 18, "update": 17.932, "loss": "2.557", "nll_loss": "1.304", "ppl": "2.47", "wps": "5589", "ups": "10", "wpb": "571.004", "bsz": "15.993", "num_updates": "38500", "lr": "0.000322329", "gnorm": "1.046", "clip": "0.000", "oom": "0.000", "wall": "4118", "train_wall": "3758"}
{"epoch": 18, "train_loss": "2.557", "train_nll_loss": "1.304", "train_ppl": "2.47", "train_wps": "5556", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "38646", "train_lr": "0.00032172", "train_gnorm": "1.048", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "4133", "train_train_wall": "3772"}
{"epoch": 18, "valid_loss": "2.647", "valid_nll_loss": "1.255", "valid_ppl": "2.39", "valid_num_updates": "38646", "valid_best_loss": "2.64741"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 18 @ 38646 updates) (writing took 0.34340953826904297 seconds)
{"epoch": 19, "update": 18.466, "loss": "2.531", "nll_loss": "1.275", "ppl": "2.42", "wps": "5564", "ups": "10", "wpb": "569.644", "bsz": "16.000", "num_updates": "39647", "lr": "0.000317632", "gnorm": "1.047", "clip": "0.000", "oom": "0.000", "wall": "4242", "train_wall": "3868"}
{"epoch": 19, "update": 18.932, "loss": "2.539", "nll_loss": "1.285", "ppl": "2.44", "wps": "5555", "ups": "10", "wpb": "567.123", "bsz": "15.993", "num_updates": "40647", "lr": "0.000313701", "gnorm": "1.052", "clip": "0.000", "oom": "0.000", "wall": "4344", "train_wall": "3963"}
{"epoch": 19, "train_loss": "2.541", "train_nll_loss": "1.287", "train_ppl": "2.44", "train_wps": "5556", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "40793", "train_lr": "0.000313139", "train_gnorm": "1.052", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "4359", "train_train_wall": "3977"}
{"epoch": 19, "valid_loss": "2.637", "valid_nll_loss": "1.241", "valid_ppl": "2.36", "valid_num_updates": "40793", "valid_best_loss": "2.63695"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 19 @ 40793 updates) (writing took 0.32451748847961426 seconds)
{"epoch": 20, "update": 19.466, "loss": "2.513", "nll_loss": "1.255", "ppl": "2.39", "wps": "5644", "ups": "10", "wpb": "574.564", "bsz": "15.986", "num_updates": "41794", "lr": "0.000309366", "gnorm": "1.040", "clip": "0.000", "oom": "0.000", "wall": "4467", "train_wall": "4073"}
{"epoch": 20, "update": 19.932, "loss": "2.526", "nll_loss": "1.270", "ppl": "2.41", "wps": "5582", "ups": "10", "wpb": "567.763", "bsz": "15.993", "num_updates": "42794", "lr": "0.00030573", "gnorm": "1.052", "clip": "0.000", "oom": "0.000", "wall": "4569", "train_wall": "4169"}
{"epoch": 20, "train_loss": "2.527", "train_nll_loss": "1.271", "train_ppl": "2.41", "train_wps": "5579", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "42940", "train_lr": "0.00030521", "train_gnorm": "1.052", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "4584", "train_train_wall": "4182"}
{"epoch": 20, "valid_loss": "2.632", "valid_nll_loss": "1.238", "valid_ppl": "2.36", "valid_num_updates": "42940", "valid_best_loss": "2.63175"}
| saved checkpoint checkpoints/transformer/v0/che/checkpoint_best.pt (epoch 20 @ 42940 updates) (writing took 0.3315269947052002 seconds)
| done training in 4589.9 seconds
Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer_iwslt_de_en', attention_dropout=0.0, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../format_delex/BPE_1_000', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=256, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=256, decoder_layerdrop=0, decoder_layers=3, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=256, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.2, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=256, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=3, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format='json', log_interval=1000, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=20, max_sentences=16, max_sentences_valid=16, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/transformer/v1/che', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='triple', target_lang='lex', task='translation', tensorboard_logdir='checkpoints/transformer/v1/log', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0)
| [triple] dictionary: 1000 types
| [lex] dictionary: 1000 types
| loaded 4313 examples from: ../format_delex/BPE_1_000/valid.triple-lex.triple
| loaded 4313 examples from: ../format_delex/BPE_1_000/valid.triple-lex.lex
| ../format_delex/BPE_1_000 valid triple-lex 4313 examples
TransformerModel(
  (encoder): TransformerEncoder(
    (embed_tokens): Embedding(1000, 256, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 256, padding_idx=1)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 256, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 256, padding_idx=1)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
)
| model transformer_iwslt_de_en, criterion LabelSmoothedCrossEntropyCriterion
| num. model params: 6310912 (num. trained: 6310912)
| training on 1 GPUs
| max tokens per GPU = None and max sentences per GPU = 16
| no existing checkpoint found checkpoints/transformer/v1/che/checkpoint_last.pt
| loading train data for epoch 0
| loaded 34338 examples from: ../format_delex/BPE_1_000/train.triple-lex.triple
| loaded 34338 examples from: ../format_delex/BPE_1_000/train.triple-lex.lex
| ../format_delex/BPE_1_000 train triple-lex 34338 examples
| NOTICE: your device may support faster training with --fp16
{"epoch": 1, "update": 0.466, "loss": "7.655", "nll_loss": "7.234", "ppl": "150.49", "wps": "5780", "ups": "10", "wpb": "577.300", "bsz": "15.986", "num_updates": "1001", "lr": "0.000250325", "gnorm": "2.115", "clip": "0.000", "oom": "0.000", "wall": "101", "train_wall": "94"}
{"epoch": 1, "update": 0.932, "loss": "6.473", "nll_loss": "5.849", "ppl": "57.63", "wps": "5660", "ups": "10", "wpb": "564.835", "bsz": "15.993", "num_updates": "2001", "lr": "0.0005003", "gnorm": "2.049", "clip": "0.000", "oom": "0.000", "wall": "201", "train_wall": "188"}
{"epoch": 1, "train_loss": "6.354", "train_nll_loss": "5.707", "train_ppl": "52.23", "train_wps": "5687", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "2147", "train_lr": "0.000536796", "train_gnorm": "2.033", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "216", "train_train_wall": "201"}
{"epoch": 1, "valid_loss": "4.469", "valid_nll_loss": "3.399", "valid_ppl": "10.55", "valid_num_updates": "2147"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 1 @ 2147 updates) (writing took 0.2503509521484375 seconds)
{"epoch": 2, "update": 1.466, "loss": "4.434", "nll_loss": "3.432", "ppl": "10.79", "wps": "5612", "ups": "10", "wpb": "560.421", "bsz": "15.986", "num_updates": "3148", "lr": "0.000787021", "gnorm": "1.762", "clip": "0.000", "oom": "0.000", "wall": "322", "train_wall": "295"}
{"epoch": 2, "update": 1.932, "loss": "4.299", "nll_loss": "3.273", "ppl": "9.67", "wps": "5649", "ups": "10", "wpb": "565.425", "bsz": "15.993", "num_updates": "4148", "lr": "0.000981998", "gnorm": "1.705", "clip": "0.000", "oom": "0.000", "wall": "422", "train_wall": "389"}
{"epoch": 2, "train_loss": "4.282", "train_nll_loss": "3.253", "train_ppl": "9.53", "train_wps": "5676", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "4294", "train_lr": "0.000965159", "train_gnorm": "1.694", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "437", "train_train_wall": "402"}
{"epoch": 2, "valid_loss": "3.755", "valid_nll_loss": "2.529", "valid_ppl": "5.77", "valid_num_updates": "4294", "valid_best_loss": "3.75498"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 2 @ 4294 updates) (writing took 0.3189423084259033 seconds)
{"epoch": 3, "update": 2.466, "loss": "3.819", "nll_loss": "2.719", "ppl": "6.59", "wps": "5670", "ups": "10", "wpb": "564.119", "bsz": "15.986", "num_updates": "5295", "lr": "0.000869155", "gnorm": "1.504", "clip": "0.000", "oom": "0.000", "wall": "543", "train_wall": "496"}
{"epoch": 3, "update": 2.932, "loss": "3.724", "nll_loss": "2.612", "ppl": "6.12", "wps": "5679", "ups": "10", "wpb": "566.214", "bsz": "15.993", "num_updates": "6295", "lr": "0.000797135", "gnorm": "1.453", "clip": "0.000", "oom": "0.000", "wall": "643", "train_wall": "590"}
{"epoch": 3, "train_loss": "3.713", "train_nll_loss": "2.600", "train_ppl": "6.06", "train_wps": "5687", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "6441", "train_lr": "0.000788049", "train_gnorm": "1.448", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "657", "train_train_wall": "603"}
{"epoch": 3, "valid_loss": "3.404", "valid_nll_loss": "2.119", "valid_ppl": "4.34", "valid_num_updates": "6441", "valid_best_loss": "3.40401"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 3 @ 6441 updates) (writing took 0.31951141357421875 seconds)
{"epoch": 4, "update": 3.466, "loss": "3.428", "nll_loss": "2.276", "ppl": "4.84", "wps": "5773", "ups": "10", "wpb": "579.127", "bsz": "15.986", "num_updates": "7442", "lr": "0.000733137", "gnorm": "1.330", "clip": "0.000", "oom": "0.000", "wall": "764", "train_wall": "698"}
{"epoch": 4, "update": 3.932, "loss": "3.370", "nll_loss": "2.211", "ppl": "4.63", "wps": "5708", "ups": "10", "wpb": "571.589", "bsz": "15.993", "num_updates": "8442", "lr": "0.000688347", "gnorm": "1.316", "clip": "0.000", "oom": "0.000", "wall": "864", "train_wall": "791"}
{"epoch": 4, "train_loss": "3.363", "train_nll_loss": "2.203", "train_ppl": "4.61", "train_wps": "5671", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "8588", "train_lr": "0.000682471", "train_gnorm": "1.317", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "879", "train_train_wall": "805"}
{"epoch": 4, "valid_loss": "3.173", "valid_nll_loss": "1.852", "valid_ppl": "3.61", "valid_num_updates": "8588", "valid_best_loss": "3.17269"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 4 @ 8588 updates) (writing took 0.34956812858581543 seconds)
{"epoch": 5, "update": 4.466, "loss": "3.197", "nll_loss": "2.016", "ppl": "4.05", "wps": "5736", "ups": "10", "wpb": "569.368", "bsz": "16.000", "num_updates": "9589", "lr": "0.000645867", "gnorm": "1.263", "clip": "0.000", "oom": "0.000", "wall": "984", "train_wall": "898"}
{"epoch": 5, "update": 4.932, "loss": "3.173", "nll_loss": "1.990", "ppl": "3.97", "wps": "5658", "ups": "10", "wpb": "563.837", "bsz": "15.993", "num_updates": "10589", "lr": "0.000614614", "gnorm": "1.258", "clip": "0.000", "oom": "0.000", "wall": "1084", "train_wall": "992"}
{"epoch": 5, "train_loss": "3.170", "train_nll_loss": "1.986", "train_ppl": "3.96", "train_wps": "5695", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "10735", "train_lr": "0.00061042", "train_gnorm": "1.254", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1099", "train_train_wall": "1005"}
{"epoch": 5, "valid_loss": "3.018", "valid_nll_loss": "1.665", "valid_ppl": "3.17", "valid_num_updates": "10735", "valid_best_loss": "3.01837"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 5 @ 10735 updates) (writing took 0.32961320877075195 seconds)
{"epoch": 6, "update": 5.466, "loss": "3.047", "nll_loss": "1.847", "ppl": "3.6", "wps": "5597", "ups": "10", "wpb": "558.641", "bsz": "15.986", "num_updates": "11736", "lr": "0.000583808", "gnorm": "1.216", "clip": "0.000", "oom": "0.000", "wall": "1205", "train_wall": "1099"}
{"epoch": 6, "update": 5.932, "loss": "3.039", "nll_loss": "1.838", "ppl": "3.58", "wps": "5701", "ups": "10", "wpb": "568.835", "bsz": "15.993", "num_updates": "12736", "lr": "0.00056042", "gnorm": "1.209", "clip": "0.000", "oom": "0.000", "wall": "1305", "train_wall": "1193"}
{"epoch": 6, "train_loss": "3.037", "train_nll_loss": "1.836", "train_ppl": "3.57", "train_wps": "5688", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "12882", "train_lr": "0.000557235", "train_gnorm": "1.210", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1320", "train_train_wall": "1206"}
{"epoch": 6, "valid_loss": "2.955", "valid_nll_loss": "1.593", "valid_ppl": "3.02", "valid_num_updates": "12882", "valid_best_loss": "2.95514"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 6 @ 12882 updates) (writing took 0.31240200996398926 seconds)
{"epoch": 7, "update": 6.466, "loss": "2.945", "nll_loss": "1.731", "ppl": "3.32", "wps": "5739", "ups": "10", "wpb": "574.266", "bsz": "16.000", "num_updates": "13883", "lr": "0.00053677", "gnorm": "1.180", "clip": "0.000", "oom": "0.000", "wall": "1426", "train_wall": "1300"}
{"epoch": 7, "update": 6.932, "loss": "2.946", "nll_loss": "1.734", "ppl": "3.33", "wps": "5682", "ups": "10", "wpb": "568.710", "bsz": "15.993", "num_updates": "14883", "lr": "0.000518424", "gnorm": "1.179", "clip": "0.000", "oom": "0.000", "wall": "1526", "train_wall": "1394"}
{"epoch": 7, "train_loss": "2.944", "train_nll_loss": "1.732", "train_ppl": "3.32", "train_wps": "5668", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "15029", "train_lr": "0.000515899", "train_gnorm": "1.180", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1541", "train_train_wall": "1408"}
{"epoch": 7, "valid_loss": "2.873", "valid_nll_loss": "1.499", "valid_ppl": "2.83", "valid_num_updates": "15029", "valid_best_loss": "2.87289"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 7 @ 15029 updates) (writing took 0.3298959732055664 seconds)
{"epoch": 8, "update": 7.466, "loss": "2.875", "nll_loss": "1.654", "ppl": "3.15", "wps": "5744", "ups": "10", "wpb": "572.825", "bsz": "15.986", "num_updates": "16030", "lr": "0.000499532", "gnorm": "1.155", "clip": "0.000", "oom": "0.000", "wall": "1647", "train_wall": "1501"}
{"epoch": 8, "update": 7.932, "loss": "2.872", "nll_loss": "1.652", "ppl": "3.14", "wps": "5691", "ups": "10", "wpb": "568.309", "bsz": "15.993", "num_updates": "17030", "lr": "0.000484644", "gnorm": "1.161", "clip": "0.000", "oom": "0.000", "wall": "1747", "train_wall": "1595"}
{"epoch": 8, "train_loss": "2.872", "train_nll_loss": "1.651", "train_ppl": "3.14", "train_wps": "5681", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "17176", "train_lr": "0.00048258", "train_gnorm": "1.161", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1762", "train_train_wall": "1609"}
{"epoch": 8, "valid_loss": "2.848", "valid_nll_loss": "1.466", "valid_ppl": "2.76", "valid_num_updates": "17176", "valid_best_loss": "2.848"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 8 @ 17176 updates) (writing took 0.3099253177642822 seconds)
{"epoch": 9, "update": 8.466, "loss": "2.814", "nll_loss": "1.587", "ppl": "3", "wps": "5760", "ups": "10", "wpb": "574.617", "bsz": "16.000", "num_updates": "18177", "lr": "0.000469104", "gnorm": "1.144", "clip": "0.000", "oom": "0.000", "wall": "1868", "train_wall": "1702"}
{"epoch": 9, "update": 8.932, "loss": "2.817", "nll_loss": "1.591", "ppl": "3.01", "wps": "5725", "ups": "10", "wpb": "569.870", "bsz": "15.993", "num_updates": "19177", "lr": "0.000456709", "gnorm": "1.148", "clip": "0.000", "oom": "0.000", "wall": "1967", "train_wall": "1795"}
{"epoch": 9, "train_loss": "2.815", "train_nll_loss": "1.588", "train_ppl": "3.01", "train_wps": "5702", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "19323", "train_lr": "0.00045498", "train_gnorm": "1.148", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1982", "train_train_wall": "1809"}
{"epoch": 9, "valid_loss": "2.808", "valid_nll_loss": "1.427", "valid_ppl": "2.69", "valid_num_updates": "19323", "valid_best_loss": "2.80804"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 9 @ 19323 updates) (writing took 0.3016014099121094 seconds)
{"epoch": 10, "update": 9.466, "loss": "2.767", "nll_loss": "1.535", "ppl": "2.9", "wps": "5708", "ups": "10", "wpb": "569.101", "bsz": "16.000", "num_updates": "20324", "lr": "0.000443635", "gnorm": "1.135", "clip": "0.000", "oom": "0.000", "wall": "2088", "train_wall": "1903"}
{"epoch": 10, "update": 9.932, "loss": "2.768", "nll_loss": "1.537", "ppl": "2.9", "wps": "5711", "ups": "10", "wpb": "569.656", "bsz": "16.000", "num_updates": "21324", "lr": "0.000433107", "gnorm": "1.136", "clip": "0.000", "oom": "0.000", "wall": "2187", "train_wall": "1996"}
{"epoch": 10, "train_loss": "2.768", "train_nll_loss": "1.536", "train_ppl": "2.9", "train_wps": "5690", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "21470", "train_lr": "0.000431632", "train_gnorm": "1.136", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2202", "train_train_wall": "2010"}
{"epoch": 10, "valid_loss": "2.778", "valid_nll_loss": "1.393", "valid_ppl": "2.63", "valid_num_updates": "21470", "valid_best_loss": "2.77846"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 10 @ 21470 updates) (writing took 0.3103668689727783 seconds)
{"epoch": 11, "update": 10.466, "loss": "2.712", "nll_loss": "1.473", "ppl": "2.78", "wps": "5557", "ups": "10", "wpb": "553.376", "bsz": "15.986", "num_updates": "22471", "lr": "0.000421909", "gnorm": "1.118", "clip": "0.000", "oom": "0.000", "wall": "2308", "train_wall": "2103"}
{"epoch": 11, "update": 10.932, "loss": "2.729", "nll_loss": "1.493", "ppl": "2.82", "wps": "5710", "ups": "10", "wpb": "569.901", "bsz": "15.993", "num_updates": "23471", "lr": "0.000412823", "gnorm": "1.121", "clip": "0.000", "oom": "0.000", "wall": "2408", "train_wall": "2197"}
{"epoch": 11, "train_loss": "2.727", "train_nll_loss": "1.491", "train_ppl": "2.81", "train_wps": "5688", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "23617", "train_lr": "0.000411545", "train_gnorm": "1.123", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2423", "train_train_wall": "2210"}
{"epoch": 11, "valid_loss": "2.741", "valid_nll_loss": "1.352", "valid_ppl": "2.55", "valid_num_updates": "23617", "valid_best_loss": "2.74093"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 11 @ 23617 updates) (writing took 0.34895825386047363 seconds)
{"epoch": 12, "update": 11.466, "loss": "2.690", "nll_loss": "1.449", "ppl": "2.73", "wps": "5788", "ups": "10", "wpb": "577.828", "bsz": "16.000", "num_updates": "24618", "lr": "0.000403091", "gnorm": "1.105", "clip": "0.000", "oom": "0.000", "wall": "2529", "train_wall": "2304"}
{"epoch": 12, "update": 11.932, "loss": "2.691", "nll_loss": "1.451", "ppl": "2.73", "wps": "5686", "ups": "10", "wpb": "567.203", "bsz": "15.993", "num_updates": "25618", "lr": "0.000395146", "gnorm": "1.119", "clip": "0.000", "oom": "0.000", "wall": "2629", "train_wall": "2397"}
{"epoch": 12, "train_loss": "2.693", "train_nll_loss": "1.453", "train_ppl": "2.74", "train_wps": "5682", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "25764", "train_lr": "0.000394025", "train_gnorm": "1.119", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2644", "train_train_wall": "2411"}
{"epoch": 12, "valid_loss": "2.723", "valid_nll_loss": "1.325", "valid_ppl": "2.51", "valid_num_updates": "25764", "valid_best_loss": "2.72305"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 12 @ 25764 updates) (writing took 0.3234212398529053 seconds)
{"epoch": 13, "update": 12.466, "loss": "2.657", "nll_loss": "1.412", "ppl": "2.66", "wps": "5667", "ups": "10", "wpb": "568.865", "bsz": "15.986", "num_updates": "26765", "lr": "0.000386586", "gnorm": "1.110", "clip": "0.000", "oom": "0.000", "wall": "2751", "train_wall": "2506"}
{"epoch": 13, "update": 12.932, "loss": "2.661", "nll_loss": "1.418", "ppl": "2.67", "wps": "5654", "ups": "10", "wpb": "566.928", "bsz": "15.993", "num_updates": "27765", "lr": "0.000379561", "gnorm": "1.114", "clip": "0.000", "oom": "0.000", "wall": "2851", "train_wall": "2599"}
{"epoch": 13, "train_loss": "2.662", "train_nll_loss": "1.419", "train_ppl": "2.67", "train_wps": "5663", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "27911", "train_lr": "0.000378567", "train_gnorm": "1.116", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2865", "train_train_wall": "2613"}
{"epoch": 13, "valid_loss": "2.694", "valid_nll_loss": "1.299", "valid_ppl": "2.46", "valid_num_updates": "27911", "valid_best_loss": "2.6935"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 13 @ 27911 updates) (writing took 0.3604011535644531 seconds)
{"epoch": 14, "update": 13.466, "loss": "2.626", "nll_loss": "1.378", "ppl": "2.6", "wps": "5661", "ups": "10", "wpb": "566.256", "bsz": "16.000", "num_updates": "28912", "lr": "0.000371955", "gnorm": "1.107", "clip": "0.000", "oom": "0.000", "wall": "2972", "train_wall": "2707"}
{"epoch": 14, "update": 13.932, "loss": "2.637", "nll_loss": "1.391", "ppl": "2.62", "wps": "5717", "ups": "10", "wpb": "569.595", "bsz": "15.993", "num_updates": "29912", "lr": "0.000365685", "gnorm": "1.112", "clip": "0.000", "oom": "0.000", "wall": "3071", "train_wall": "2800"}
{"epoch": 14, "train_loss": "2.637", "train_nll_loss": "1.391", "train_ppl": "2.62", "train_wps": "5697", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "30058", "train_lr": "0.000364796", "train_gnorm": "1.112", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3086", "train_train_wall": "2814"}
{"epoch": 14, "valid_loss": "2.683", "valid_nll_loss": "1.284", "valid_ppl": "2.43", "valid_num_updates": "30058", "valid_best_loss": "2.68257"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 14 @ 30058 updates) (writing took 0.335176944732666 seconds)
{"epoch": 15, "update": 14.466, "loss": "2.607", "nll_loss": "1.357", "ppl": "2.56", "wps": "5776", "ups": "10", "wpb": "574.982", "bsz": "15.986", "num_updates": "31059", "lr": "0.000358869", "gnorm": "1.097", "clip": "0.000", "oom": "0.000", "wall": "3192", "train_wall": "2907"}
{"epoch": 15, "update": 14.932, "loss": "2.614", "nll_loss": "1.366", "ppl": "2.58", "wps": "5727", "ups": "10", "wpb": "571.160", "bsz": "15.993", "num_updates": "32059", "lr": "0.000353228", "gnorm": "1.109", "clip": "0.000", "oom": "0.000", "wall": "3292", "train_wall": "3001"}
{"epoch": 15, "train_loss": "2.614", "train_nll_loss": "1.366", "train_ppl": "2.58", "train_wps": "5693", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "32205", "train_lr": "0.000352426", "train_gnorm": "1.110", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3306", "train_train_wall": "3014"}
{"epoch": 15, "valid_loss": "2.681", "valid_nll_loss": "1.280", "valid_ppl": "2.43", "valid_num_updates": "32205", "valid_best_loss": "2.68097"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 15 @ 32205 updates) (writing took 0.35289907455444336 seconds)
{"epoch": 16, "update": 15.466, "loss": "2.577", "nll_loss": "1.325", "ppl": "2.51", "wps": "5557", "ups": "10", "wpb": "551.835", "bsz": "16.000", "num_updates": "33206", "lr": "0.000347074", "gnorm": "1.109", "clip": "0.000", "oom": "0.000", "wall": "3412", "train_wall": "3107"}
{"epoch": 16, "update": 15.932, "loss": "2.592", "nll_loss": "1.342", "ppl": "2.53", "wps": "5692", "ups": "10", "wpb": "566.442", "bsz": "15.993", "num_updates": "34206", "lr": "0.000341963", "gnorm": "1.107", "clip": "0.000", "oom": "0.000", "wall": "3512", "train_wall": "3201"}
{"epoch": 16, "train_loss": "2.593", "train_nll_loss": "1.343", "train_ppl": "2.54", "train_wps": "5701", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "34352", "train_lr": "0.000341235", "train_gnorm": "1.108", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3526", "train_train_wall": "3215"}
{"epoch": 16, "valid_loss": "2.661", "valid_nll_loss": "1.258", "valid_ppl": "2.39", "valid_num_updates": "34352", "valid_best_loss": "2.66139"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 16 @ 34352 updates) (writing took 0.32627272605895996 seconds)
{"epoch": 17, "update": 16.466, "loss": "2.572", "nll_loss": "1.319", "ppl": "2.49", "wps": "5681", "ups": "10", "wpb": "567.820", "bsz": "16.000", "num_updates": "35353", "lr": "0.00033637", "gnorm": "1.104", "clip": "0.000", "oom": "0.000", "wall": "3633", "train_wall": "3308"}
{"epoch": 17, "update": 16.932, "loss": "2.573", "nll_loss": "1.321", "ppl": "2.5", "wps": "5691", "ups": "10", "wpb": "568.294", "bsz": "16.000", "num_updates": "36353", "lr": "0.000331711", "gnorm": "1.112", "clip": "0.000", "oom": "0.000", "wall": "3733", "train_wall": "3402"}
{"epoch": 17, "train_loss": "2.572", "train_nll_loss": "1.320", "train_ppl": "2.5", "train_wps": "5687", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "36499", "train_lr": "0.000331047", "train_gnorm": "1.112", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3747", "train_train_wall": "3415"}
{"epoch": 17, "valid_loss": "2.656", "valid_nll_loss": "1.254", "valid_ppl": "2.39", "valid_num_updates": "36499", "valid_best_loss": "2.6556"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 17 @ 36499 updates) (writing took 0.3437983989715576 seconds)
{"epoch": 18, "update": 17.466, "loss": "2.546", "nll_loss": "1.290", "ppl": "2.45", "wps": "5771", "ups": "10", "wpb": "576.940", "bsz": "15.986", "num_updates": "37500", "lr": "0.000326599", "gnorm": "1.107", "clip": "0.000", "oom": "0.000", "wall": "3854", "train_wall": "3509"}
{"epoch": 18, "update": 17.932, "loss": "2.555", "nll_loss": "1.300", "ppl": "2.46", "wps": "5715", "ups": "10", "wpb": "571.004", "bsz": "15.993", "num_updates": "38500", "lr": "0.000322329", "gnorm": "1.112", "clip": "0.000", "oom": "0.000", "wall": "3953", "train_wall": "3603"}
{"epoch": 18, "train_loss": "2.555", "train_nll_loss": "1.301", "train_ppl": "2.46", "train_wps": "5681", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "38646", "train_lr": "0.00032172", "train_gnorm": "1.115", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3968", "train_train_wall": "3616"}
{"epoch": 18, "valid_loss": "2.638", "valid_nll_loss": "1.238", "valid_ppl": "2.36", "valid_num_updates": "38646", "valid_best_loss": "2.63832"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 18 @ 38646 updates) (writing took 0.3753538131713867 seconds)
{"epoch": 19, "update": 18.466, "loss": "2.531", "nll_loss": "1.273", "ppl": "2.42", "wps": "5687", "ups": "10", "wpb": "569.644", "bsz": "16.000", "num_updates": "39647", "lr": "0.000317632", "gnorm": "1.106", "clip": "0.000", "oom": "0.000", "wall": "4075", "train_wall": "3710"}
{"epoch": 19, "update": 18.932, "loss": "2.538", "nll_loss": "1.282", "ppl": "2.43", "wps": "5669", "ups": "10", "wpb": "567.123", "bsz": "15.993", "num_updates": "40647", "lr": "0.000313701", "gnorm": "1.113", "clip": "0.000", "oom": "0.000", "wall": "4174", "train_wall": "3804"}
{"epoch": 19, "train_loss": "2.539", "train_nll_loss": "1.283", "train_ppl": "2.43", "train_wps": "5673", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "40793", "train_lr": "0.000313139", "train_gnorm": "1.112", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "4189", "train_train_wall": "3818"}
{"epoch": 19, "valid_loss": "2.625", "valid_nll_loss": "1.222", "valid_ppl": "2.33", "valid_num_updates": "40793", "valid_best_loss": "2.6247"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 19 @ 40793 updates) (writing took 0.32578349113464355 seconds)
{"epoch": 20, "update": 19.466, "loss": "2.511", "nll_loss": "1.252", "ppl": "2.38", "wps": "5703", "ups": "10", "wpb": "574.564", "bsz": "15.986", "num_updates": "41794", "lr": "0.000309366", "gnorm": "1.097", "clip": "0.000", "oom": "0.000", "wall": "4296", "train_wall": "3912"}
{"epoch": 20, "update": 19.932, "loss": "2.523", "nll_loss": "1.266", "ppl": "2.4", "wps": "5663", "ups": "10", "wpb": "567.763", "bsz": "15.993", "num_updates": "42794", "lr": "0.00030573", "gnorm": "1.110", "clip": "0.000", "oom": "0.000", "wall": "4396", "train_wall": "4006"}
{"epoch": 20, "train_loss": "2.524", "train_nll_loss": "1.267", "train_ppl": "2.41", "train_wps": "5658", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "42940", "train_lr": "0.00030521", "train_gnorm": "1.111", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "4411", "train_train_wall": "4020"}
{"epoch": 20, "valid_loss": "2.618", "valid_nll_loss": "1.215", "valid_ppl": "2.32", "valid_num_updates": "42940", "valid_best_loss": "2.61786"}
| saved checkpoint checkpoints/transformer/v1/che/checkpoint_best.pt (epoch 20 @ 42940 updates) (writing took 0.33986806869506836 seconds)
| done training in 4416.5 seconds
Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer_iwslt_de_en', attention_dropout=0.0, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=True, curriculum=0, data='../format_delex/BPE_1_000', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=256, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=256, decoder_layerdrop=0, decoder_layers=3, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=256, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.2, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=256, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=3, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format='json', log_interval=1000, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=20, max_sentences=16, max_sentences_valid=16, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/transformer/v2/che', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='triple', target_lang='lex', task='translation', tensorboard_logdir='checkpoints/transformer/v2/log', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0)
| [triple] dictionary: 1000 types
| [lex] dictionary: 1000 types
| loaded 4313 examples from: ../format_delex/BPE_1_000/valid.triple-lex.triple
| loaded 4313 examples from: ../format_delex/BPE_1_000/valid.triple-lex.lex
| ../format_delex/BPE_1_000 valid triple-lex 4313 examples
TransformerModel(
  (encoder): TransformerEncoder(
    (embed_tokens): Embedding(1000, 256, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 256, padding_idx=1)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 256, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
)
| model transformer_iwslt_de_en, criterion LabelSmoothedCrossEntropyCriterion
| num. model params: 6048256 (num. trained: 6048256)
| training on 1 GPUs
| max tokens per GPU = None and max sentences per GPU = 16
| no existing checkpoint found checkpoints/transformer/v2/che/checkpoint_last.pt
| loading train data for epoch 0
| loaded 34338 examples from: ../format_delex/BPE_1_000/train.triple-lex.triple
| loaded 34338 examples from: ../format_delex/BPE_1_000/train.triple-lex.lex
| ../format_delex/BPE_1_000 train triple-lex 34338 examples
| NOTICE: your device may support faster training with --fp16
{"epoch": 1, "update": 0.466, "loss": "7.684", "nll_loss": "7.266", "ppl": "153.95", "wps": "5713", "ups": "10", "wpb": "577.300", "bsz": "15.986", "num_updates": "1001", "lr": "0.000250325", "gnorm": "2.148", "clip": "0.000", "oom": "0.000", "wall": "103", "train_wall": "95"}
{"epoch": 1, "update": 0.932, "loss": "6.531", "nll_loss": "5.913", "ppl": "60.24", "wps": "5591", "ups": "10", "wpb": "564.835", "bsz": "15.993", "num_updates": "2001", "lr": "0.0005003", "gnorm": "2.074", "clip": "0.000", "oom": "0.000", "wall": "204", "train_wall": "190"}
{"epoch": 1, "train_loss": "6.411", "train_nll_loss": "5.771", "train_ppl": "54.6", "train_wps": "5619", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "2147", "train_lr": "0.000536796", "train_gnorm": "2.055", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "218", "train_train_wall": "204"}
{"epoch": 1, "valid_loss": "4.550", "valid_nll_loss": "3.497", "valid_ppl": "11.29", "valid_num_updates": "2147"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 1 @ 2147 updates) (writing took 0.2709314823150635 seconds)
{"epoch": 2, "update": 1.466, "loss": "4.467", "nll_loss": "3.469", "ppl": "11.08", "wps": "5548", "ups": "10", "wpb": "560.421", "bsz": "15.986", "num_updates": "3148", "lr": "0.000787021", "gnorm": "1.716", "clip": "0.000", "oom": "0.000", "wall": "326", "train_wall": "299"}
{"epoch": 2, "update": 1.932, "loss": "4.302", "nll_loss": "3.277", "ppl": "9.69", "wps": "5605", "ups": "10", "wpb": "565.425", "bsz": "15.993", "num_updates": "4148", "lr": "0.000981998", "gnorm": "1.643", "clip": "0.000", "oom": "0.000", "wall": "427", "train_wall": "393"}
{"epoch": 2, "train_loss": "4.281", "train_nll_loss": "3.252", "train_ppl": "9.53", "train_wps": "5626", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "4294", "train_lr": "0.000965159", "train_gnorm": "1.631", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "442", "train_train_wall": "407"}
{"epoch": 2, "valid_loss": "3.715", "valid_nll_loss": "2.487", "valid_ppl": "5.61", "valid_num_updates": "4294", "valid_best_loss": "3.71516"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 2 @ 4294 updates) (writing took 0.3237476348876953 seconds)
{"epoch": 3, "update": 2.466, "loss": "3.763", "nll_loss": "2.657", "ppl": "6.31", "wps": "5589", "ups": "10", "wpb": "564.119", "bsz": "15.986", "num_updates": "5295", "lr": "0.000869155", "gnorm": "1.412", "clip": "0.000", "oom": "0.000", "wall": "550", "train_wall": "502"}
{"epoch": 3, "update": 2.932, "loss": "3.668", "nll_loss": "2.550", "ppl": "5.85", "wps": "5604", "ups": "10", "wpb": "566.214", "bsz": "15.993", "num_updates": "6295", "lr": "0.000797135", "gnorm": "1.364", "clip": "0.000", "oom": "0.000", "wall": "651", "train_wall": "598"}
{"epoch": 3, "train_loss": "3.658", "train_nll_loss": "2.538", "train_ppl": "5.81", "train_wps": "5620", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "6441", "train_lr": "0.000788049", "train_gnorm": "1.358", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "665", "train_train_wall": "611"}
{"epoch": 3, "valid_loss": "3.333", "valid_nll_loss": "2.044", "valid_ppl": "4.12", "valid_num_updates": "6441", "valid_best_loss": "3.33288"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 3 @ 6441 updates) (writing took 0.31668710708618164 seconds)
{"epoch": 4, "update": 3.466, "loss": "3.376", "nll_loss": "2.218", "ppl": "4.65", "wps": "5758", "ups": "10", "wpb": "579.127", "bsz": "15.986", "num_updates": "7442", "lr": "0.000733137", "gnorm": "1.248", "clip": "0.000", "oom": "0.000", "wall": "773", "train_wall": "706"}
{"epoch": 4, "update": 3.932, "loss": "3.324", "nll_loss": "2.160", "ppl": "4.47", "wps": "5667", "ups": "10", "wpb": "571.589", "bsz": "15.993", "num_updates": "8442", "lr": "0.000688347", "gnorm": "1.234", "clip": "0.000", "oom": "0.000", "wall": "874", "train_wall": "801"}
{"epoch": 4, "train_loss": "3.318", "train_nll_loss": "2.153", "train_ppl": "4.45", "train_wps": "5628", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "8588", "train_lr": "0.000682471", "train_gnorm": "1.236", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "889", "train_train_wall": "815"}
{"epoch": 4, "valid_loss": "3.132", "valid_nll_loss": "1.814", "valid_ppl": "3.52", "valid_num_updates": "8588", "valid_best_loss": "3.13198"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 4 @ 8588 updates) (writing took 0.31650543212890625 seconds)
{"epoch": 5, "update": 4.466, "loss": "3.159", "nll_loss": "1.974", "ppl": "3.93", "wps": "5658", "ups": "10", "wpb": "569.368", "bsz": "16.000", "num_updates": "9589", "lr": "0.000645867", "gnorm": "1.186", "clip": "0.000", "oom": "0.000", "wall": "996", "train_wall": "910"}
{"epoch": 5, "update": 4.932, "loss": "3.138", "nll_loss": "1.951", "ppl": "3.87", "wps": "5592", "ups": "10", "wpb": "563.837", "bsz": "15.993", "num_updates": "10589", "lr": "0.000614614", "gnorm": "1.182", "clip": "0.000", "oom": "0.000", "wall": "1097", "train_wall": "1005"}
{"epoch": 5, "train_loss": "3.135", "train_nll_loss": "1.948", "train_ppl": "3.86", "train_wps": "5630", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "10735", "train_lr": "0.00061042", "train_gnorm": "1.179", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1112", "train_train_wall": "1019"}
{"epoch": 5, "valid_loss": "3.000", "valid_nll_loss": "1.652", "valid_ppl": "3.14", "valid_num_updates": "10735", "valid_best_loss": "3.00005"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 5 @ 10735 updates) (writing took 0.30977463722229004 seconds)
{"epoch": 6, "update": 5.466, "loss": "3.019", "nll_loss": "1.816", "ppl": "3.52", "wps": "5552", "ups": "10", "wpb": "558.641", "bsz": "15.986", "num_updates": "11736", "lr": "0.000583808", "gnorm": "1.148", "clip": "0.000", "oom": "0.000", "wall": "1219", "train_wall": "1114"}
{"epoch": 6, "update": 5.932, "loss": "3.012", "nll_loss": "1.809", "ppl": "3.51", "wps": "5660", "ups": "10", "wpb": "568.835", "bsz": "15.993", "num_updates": "12736", "lr": "0.00056042", "gnorm": "1.139", "clip": "0.000", "oom": "0.000", "wall": "1320", "train_wall": "1208"}
{"epoch": 6, "train_loss": "3.010", "train_nll_loss": "1.808", "train_ppl": "3.5", "train_wps": "5641", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "12882", "train_lr": "0.000557235", "train_gnorm": "1.139", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1335", "train_train_wall": "1222"}
{"epoch": 6, "valid_loss": "2.917", "valid_nll_loss": "1.561", "valid_ppl": "2.95", "valid_num_updates": "12882", "valid_best_loss": "2.91705"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 6 @ 12882 updates) (writing took 0.31136274337768555 seconds)
{"epoch": 7, "update": 6.466, "loss": "2.923", "nll_loss": "1.708", "ppl": "3.27", "wps": "5691", "ups": "10", "wpb": "574.266", "bsz": "16.000", "num_updates": "13883", "lr": "0.00053677", "gnorm": "1.113", "clip": "0.000", "oom": "0.000", "wall": "1442", "train_wall": "1317"}
{"epoch": 7, "update": 6.932, "loss": "2.923", "nll_loss": "1.710", "ppl": "3.27", "wps": "5632", "ups": "10", "wpb": "568.710", "bsz": "15.993", "num_updates": "14883", "lr": "0.000518424", "gnorm": "1.113", "clip": "0.000", "oom": "0.000", "wall": "1543", "train_wall": "1413"}
{"epoch": 7, "train_loss": "2.921", "train_nll_loss": "1.708", "train_ppl": "3.27", "train_wps": "5620", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "15029", "train_lr": "0.000515899", "train_gnorm": "1.112", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1558", "train_train_wall": "1427"}
{"epoch": 7, "valid_loss": "2.850", "valid_nll_loss": "1.483", "valid_ppl": "2.79", "valid_num_updates": "15029", "valid_best_loss": "2.8503"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 7 @ 15029 updates) (writing took 0.30373549461364746 seconds)
{"epoch": 8, "update": 7.466, "loss": "2.855", "nll_loss": "1.634", "ppl": "3.1", "wps": "5713", "ups": "10", "wpb": "572.825", "bsz": "15.986", "num_updates": "16030", "lr": "0.000499532", "gnorm": "1.090", "clip": "0.000", "oom": "0.000", "wall": "1665", "train_wall": "1521"}
{"epoch": 8, "update": 7.932, "loss": "2.853", "nll_loss": "1.632", "ppl": "3.1", "wps": "5679", "ups": "10", "wpb": "568.309", "bsz": "15.993", "num_updates": "17030", "lr": "0.000484644", "gnorm": "1.096", "clip": "0.000", "oom": "0.000", "wall": "1765", "train_wall": "1615"}
{"epoch": 8, "train_loss": "2.852", "train_nll_loss": "1.631", "train_ppl": "3.1", "train_wps": "5669", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "17176", "train_lr": "0.00048258", "train_gnorm": "1.095", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1780", "train_train_wall": "1629"}
{"epoch": 8, "valid_loss": "2.816", "valid_nll_loss": "1.440", "valid_ppl": "2.71", "valid_num_updates": "17176", "valid_best_loss": "2.81622"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 8 @ 17176 updates) (writing took 0.31884121894836426 seconds)
{"epoch": 9, "update": 8.466, "loss": "2.797", "nll_loss": "1.568", "ppl": "2.97", "wps": "5702", "ups": "10", "wpb": "574.617", "bsz": "16.000", "num_updates": "18177", "lr": "0.000469104", "gnorm": "1.078", "clip": "0.000", "oom": "0.000", "wall": "1887", "train_wall": "1724"}
{"epoch": 9, "update": 8.932, "loss": "2.800", "nll_loss": "1.573", "ppl": "2.97", "wps": "5651", "ups": "10", "wpb": "569.870", "bsz": "15.993", "num_updates": "19177", "lr": "0.000456709", "gnorm": "1.082", "clip": "0.000", "oom": "0.000", "wall": "1988", "train_wall": "1819"}
{"epoch": 9, "train_loss": "2.798", "train_nll_loss": "1.571", "train_ppl": "2.97", "train_wps": "5628", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "19323", "train_lr": "0.00045498", "train_gnorm": "1.082", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2003", "train_train_wall": "1833"}
{"epoch": 9, "valid_loss": "2.782", "valid_nll_loss": "1.407", "valid_ppl": "2.65", "valid_num_updates": "19323", "valid_best_loss": "2.782"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 9 @ 19323 updates) (writing took 0.3064444065093994 seconds)
{"epoch": 10, "update": 9.466, "loss": "2.752", "nll_loss": "1.519", "ppl": "2.87", "wps": "5644", "ups": "10", "wpb": "569.101", "bsz": "16.000", "num_updates": "20324", "lr": "0.000443635", "gnorm": "1.069", "clip": "0.000", "oom": "0.000", "wall": "2111", "train_wall": "1928"}
{"epoch": 10, "update": 9.932, "loss": "2.753", "nll_loss": "1.521", "ppl": "2.87", "wps": "5649", "ups": "10", "wpb": "569.656", "bsz": "16.000", "num_updates": "21324", "lr": "0.000433107", "gnorm": "1.071", "clip": "0.000", "oom": "0.000", "wall": "2212", "train_wall": "2023"}
{"epoch": 10, "train_loss": "2.753", "train_nll_loss": "1.520", "train_ppl": "2.87", "train_wps": "5632", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "21470", "train_lr": "0.000431632", "train_gnorm": "1.071", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2226", "train_train_wall": "2036"}
{"epoch": 10, "valid_loss": "2.751", "valid_nll_loss": "1.365", "valid_ppl": "2.58", "valid_num_updates": "21470", "valid_best_loss": "2.7513"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 10 @ 21470 updates) (writing took 0.2929201126098633 seconds)
{"epoch": 11, "update": 10.466, "loss": "2.701", "nll_loss": "1.462", "ppl": "2.76", "wps": "5479", "ups": "10", "wpb": "553.376", "bsz": "15.986", "num_updates": "22471", "lr": "0.000421909", "gnorm": "1.058", "clip": "0.000", "oom": "0.000", "wall": "2334", "train_wall": "2132"}
{"epoch": 11, "update": 10.932, "loss": "2.718", "nll_loss": "1.482", "ppl": "2.79", "wps": "5660", "ups": "10", "wpb": "569.901", "bsz": "15.993", "num_updates": "23471", "lr": "0.000412823", "gnorm": "1.061", "clip": "0.000", "oom": "0.000", "wall": "2434", "train_wall": "2226"}
{"epoch": 11, "train_loss": "2.716", "train_nll_loss": "1.479", "train_ppl": "2.79", "train_wps": "5637", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "23617", "train_lr": "0.000411545", "train_gnorm": "1.063", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2449", "train_train_wall": "2240"}
{"epoch": 11, "valid_loss": "2.721", "valid_nll_loss": "1.337", "valid_ppl": "2.53", "valid_num_updates": "23617", "valid_best_loss": "2.72085"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 11 @ 23617 updates) (writing took 0.2942214012145996 seconds)
{"epoch": 12, "update": 11.466, "loss": "2.677", "nll_loss": "1.436", "ppl": "2.7", "wps": "5744", "ups": "10", "wpb": "577.828", "bsz": "16.000", "num_updates": "24618", "lr": "0.000403091", "gnorm": "1.045", "clip": "0.000", "oom": "0.000", "wall": "2556", "train_wall": "2335"}
{"epoch": 12, "update": 11.932, "loss": "2.680", "nll_loss": "1.439", "ppl": "2.71", "wps": "5635", "ups": "10", "wpb": "567.203", "bsz": "15.993", "num_updates": "25618", "lr": "0.000395146", "gnorm": "1.055", "clip": "0.000", "oom": "0.000", "wall": "2657", "train_wall": "2429"}
{"epoch": 12, "train_loss": "2.682", "train_nll_loss": "1.441", "train_ppl": "2.72", "train_wps": "5637", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "25764", "train_lr": "0.000394025", "train_gnorm": "1.056", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2672", "train_train_wall": "2443"}
{"epoch": 12, "valid_loss": "2.705", "valid_nll_loss": "1.316", "valid_ppl": "2.49", "valid_num_updates": "25764", "valid_best_loss": "2.70513"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 12 @ 25764 updates) (writing took 0.29938197135925293 seconds)
{"epoch": 13, "update": 12.466, "loss": "2.648", "nll_loss": "1.403", "ppl": "2.65", "wps": "5665", "ups": "10", "wpb": "568.865", "bsz": "15.986", "num_updates": "26765", "lr": "0.000386586", "gnorm": "1.046", "clip": "0.000", "oom": "0.000", "wall": "2779", "train_wall": "2538"}
{"epoch": 13, "update": 12.932, "loss": "2.653", "nll_loss": "1.409", "ppl": "2.66", "wps": "5637", "ups": "10", "wpb": "566.928", "bsz": "15.993", "num_updates": "27765", "lr": "0.000379561", "gnorm": "1.050", "clip": "0.000", "oom": "0.000", "wall": "2880", "train_wall": "2633"}
{"epoch": 13, "train_loss": "2.654", "train_nll_loss": "1.411", "train_ppl": "2.66", "train_wps": "5641", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "27911", "train_lr": "0.000378567", "train_gnorm": "1.051", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2895", "train_train_wall": "2647"}
{"epoch": 13, "valid_loss": "2.676", "valid_nll_loss": "1.282", "valid_ppl": "2.43", "valid_num_updates": "27911", "valid_best_loss": "2.6765"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 13 @ 27911 updates) (writing took 0.3410608768463135 seconds)
{"epoch": 14, "update": 13.466, "loss": "2.616", "nll_loss": "1.368", "ppl": "2.58", "wps": "5599", "ups": "10", "wpb": "566.256", "bsz": "16.000", "num_updates": "28912", "lr": "0.000371955", "gnorm": "1.042", "clip": "0.000", "oom": "0.000", "wall": "3003", "train_wall": "2742"}
{"epoch": 14, "update": 13.932, "loss": "2.627", "nll_loss": "1.381", "ppl": "2.6", "wps": "5621", "ups": "10", "wpb": "569.595", "bsz": "15.993", "num_updates": "29912", "lr": "0.000365685", "gnorm": "1.047", "clip": "0.000", "oom": "0.000", "wall": "3104", "train_wall": "2838"}
{"epoch": 14, "train_loss": "2.627", "train_nll_loss": "1.381", "train_ppl": "2.6", "train_wps": "5603", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "30058", "train_lr": "0.000364796", "train_gnorm": "1.047", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3119", "train_train_wall": "2852"}
{"epoch": 14, "valid_loss": "2.666", "valid_nll_loss": "1.273", "valid_ppl": "2.42", "valid_num_updates": "30058", "valid_best_loss": "2.66647"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 14 @ 30058 updates) (writing took 0.30708980560302734 seconds)
{"epoch": 15, "update": 14.466, "loss": "2.600", "nll_loss": "1.351", "ppl": "2.55", "wps": "5669", "ups": "10", "wpb": "574.982", "bsz": "15.986", "num_updates": "31059", "lr": "0.000358869", "gnorm": "1.034", "clip": "0.000", "oom": "0.000", "wall": "3227", "train_wall": "2947"}
{"epoch": 15, "update": 14.932, "loss": "2.605", "nll_loss": "1.357", "ppl": "2.56", "wps": "5627", "ups": "10", "wpb": "571.160", "bsz": "15.993", "num_updates": "32059", "lr": "0.000353228", "gnorm": "1.040", "clip": "0.000", "oom": "0.000", "wall": "3329", "train_wall": "3042"}
{"epoch": 15, "train_loss": "2.604", "train_nll_loss": "1.356", "train_ppl": "2.56", "train_wps": "5592", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "32205", "train_lr": "0.000352426", "train_gnorm": "1.042", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3344", "train_train_wall": "3056"}
{"epoch": 15, "valid_loss": "2.673", "valid_nll_loss": "1.279", "valid_ppl": "2.43", "valid_num_updates": "32205", "valid_best_loss": "2.66647"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_last.pt (epoch 15 @ 32205 updates) (writing took 0.18017864227294922 seconds)
{"epoch": 16, "update": 15.466, "loss": "2.567", "nll_loss": "1.314", "ppl": "2.49", "wps": "5433", "ups": "10", "wpb": "551.835", "bsz": "16.000", "num_updates": "33206", "lr": "0.000347074", "gnorm": "1.041", "clip": "0.000", "oom": "0.000", "wall": "3452", "train_wall": "3152"}
{"epoch": 16, "update": 15.932, "loss": "2.582", "nll_loss": "1.331", "ppl": "2.52", "wps": "5586", "ups": "10", "wpb": "566.442", "bsz": "15.993", "num_updates": "34206", "lr": "0.000341963", "gnorm": "1.042", "clip": "0.000", "oom": "0.000", "wall": "3553", "train_wall": "3247"}
{"epoch": 16, "train_loss": "2.583", "train_nll_loss": "1.333", "train_ppl": "2.52", "train_wps": "5601", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "34352", "train_lr": "0.000341235", "train_gnorm": "1.042", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3568", "train_train_wall": "3260"}
{"epoch": 16, "valid_loss": "2.642", "valid_nll_loss": "1.244", "valid_ppl": "2.37", "valid_num_updates": "34352", "valid_best_loss": "2.64229"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 16 @ 34352 updates) (writing took 0.3129246234893799 seconds)
{"epoch": 17, "update": 16.466, "loss": "2.563", "nll_loss": "1.310", "ppl": "2.48", "wps": "5562", "ups": "10", "wpb": "567.820", "bsz": "16.000", "num_updates": "35353", "lr": "0.00033637", "gnorm": "1.028", "clip": "0.000", "oom": "0.000", "wall": "3677", "train_wall": "3356"}
{"epoch": 17, "update": 16.932, "loss": "2.565", "nll_loss": "1.312", "ppl": "2.48", "wps": "5601", "ups": "10", "wpb": "568.294", "bsz": "16.000", "num_updates": "36353", "lr": "0.000331711", "gnorm": "1.038", "clip": "0.000", "oom": "0.000", "wall": "3777", "train_wall": "3451"}
{"epoch": 17, "train_loss": "2.564", "train_nll_loss": "1.312", "train_ppl": "2.48", "train_wps": "5594", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "36499", "train_lr": "0.000331047", "train_gnorm": "1.039", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3792", "train_train_wall": "3465"}
{"epoch": 17, "valid_loss": "2.631", "valid_nll_loss": "1.236", "valid_ppl": "2.36", "valid_num_updates": "36499", "valid_best_loss": "2.63133"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 17 @ 36499 updates) (writing took 0.33455920219421387 seconds)
{"epoch": 18, "update": 17.466, "loss": "2.538", "nll_loss": "1.282", "ppl": "2.43", "wps": "5688", "ups": "10", "wpb": "576.940", "bsz": "15.986", "num_updates": "37500", "lr": "0.000326599", "gnorm": "1.025", "clip": "0.000", "oom": "0.000", "wall": "3900", "train_wall": "3560"}
{"epoch": 18, "update": 17.932, "loss": "2.547", "nll_loss": "1.293", "ppl": "2.45", "wps": "5632", "ups": "10", "wpb": "571.004", "bsz": "15.993", "num_updates": "38500", "lr": "0.000322329", "gnorm": "1.034", "clip": "0.000", "oom": "0.000", "wall": "4002", "train_wall": "3655"}
{"epoch": 18, "train_loss": "2.548", "train_nll_loss": "1.293", "train_ppl": "2.45", "train_wps": "5598", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "38646", "train_lr": "0.00032172", "train_gnorm": "1.036", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "4017", "train_train_wall": "3669"}
{"epoch": 18, "valid_loss": "2.623", "valid_nll_loss": "1.223", "valid_ppl": "2.34", "valid_num_updates": "38646", "valid_best_loss": "2.62278"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 18 @ 38646 updates) (writing took 0.32578587532043457 seconds)
{"epoch": 19, "update": 18.466, "loss": "2.523", "nll_loss": "1.266", "ppl": "2.41", "wps": "5473", "ups": "10", "wpb": "569.644", "bsz": "16.000", "num_updates": "39647", "lr": "0.000317632", "gnorm": "1.032", "clip": "0.000", "oom": "0.000", "wall": "4127", "train_wall": "3766"}
{"epoch": 19, "update": 18.932, "loss": "2.530", "nll_loss": "1.274", "ppl": "2.42", "wps": "5127", "ups": "9", "wpb": "567.123", "bsz": "15.993", "num_updates": "40647", "lr": "0.000313701", "gnorm": "1.039", "clip": "0.000", "oom": "0.000", "wall": "4244", "train_wall": "3876"}
{"epoch": 19, "train_loss": "2.532", "train_nll_loss": "1.276", "train_ppl": "2.42", "train_wps": "5109", "train_ups": "9", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "40793", "train_lr": "0.000313139", "train_gnorm": "1.038", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "4262", "train_train_wall": "3892"}
{"epoch": 19, "valid_loss": "2.617", "valid_nll_loss": "1.216", "valid_ppl": "2.32", "valid_num_updates": "40793", "valid_best_loss": "2.61681"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 19 @ 40793 updates) (writing took 0.37464118003845215 seconds)
{"epoch": 20, "update": 19.466, "loss": "2.503", "nll_loss": "1.243", "ppl": "2.37", "wps": "4876", "ups": "8", "wpb": "574.564", "bsz": "15.986", "num_updates": "41794", "lr": "0.000309366", "gnorm": "1.030", "clip": "0.000", "oom": "0.000", "wall": "4388", "train_wall": "4002"}
{"epoch": 20, "update": 19.932, "loss": "2.516", "nll_loss": "1.258", "ppl": "2.39", "wps": "4832", "ups": "9", "wpb": "567.763", "bsz": "15.993", "num_updates": "42794", "lr": "0.00030573", "gnorm": "1.038", "clip": "0.000", "oom": "0.000", "wall": "4505", "train_wall": "4111"}
{"epoch": 20, "train_loss": "2.517", "train_nll_loss": "1.259", "train_ppl": "2.39", "train_wps": "4843", "train_ups": "9", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "42940", "train_lr": "0.00030521", "train_gnorm": "1.038", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "4521", "train_train_wall": "4127"}
{"epoch": 20, "valid_loss": "2.602", "valid_nll_loss": "1.203", "valid_ppl": "2.3", "valid_num_updates": "42940", "valid_best_loss": "2.60205"}
| saved checkpoint checkpoints/transformer/v2/che/checkpoint_best.pt (epoch 20 @ 42940 updates) (writing took 0.3624758720397949 seconds)
| done training in 4529.0 seconds
Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer_iwslt_de_en', attention_dropout=0.0, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../format_delex/BPE_1_000', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=256, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=256, decoder_layerdrop=0, decoder_layers=3, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=256, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.2, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=256, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=3, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format='json', log_interval=1000, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=20, max_sentences=16, max_sentences_valid=16, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/transformer/v3/che', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='triple', target_lang='lex', task='translation', tensorboard_logdir='checkpoints/transformer/v3/log', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0)
| [triple] dictionary: 1000 types
| [lex] dictionary: 1000 types
| loaded 4313 examples from: ../format_delex/BPE_1_000/valid.triple-lex.triple
| loaded 4313 examples from: ../format_delex/BPE_1_000/valid.triple-lex.lex
| ../format_delex/BPE_1_000 valid triple-lex 4313 examples
TransformerModel(
  (encoder): TransformerEncoder(
    (embed_tokens): Embedding(1000, 256, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 256, padding_idx=1)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 256, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
)
| model transformer_iwslt_de_en, criterion LabelSmoothedCrossEntropyCriterion
| num. model params: 6048256 (num. trained: 6048256)
| training on 1 GPUs
| max tokens per GPU = None and max sentences per GPU = 16
| no existing checkpoint found checkpoints/transformer/v3/che/checkpoint_last.pt
| loading train data for epoch 0
| loaded 34338 examples from: ../format_delex/BPE_1_000/train.triple-lex.triple
| loaded 34338 examples from: ../format_delex/BPE_1_000/train.triple-lex.lex
| ../format_delex/BPE_1_000 train triple-lex 34338 examples
| NOTICE: your device may support faster training with --fp16
{"epoch": 1, "update": 0.466, "loss": "7.762", "nll_loss": "7.355", "ppl": "163.72", "wps": "5255", "ups": "9", "wpb": "577.300", "bsz": "15.986", "num_updates": "1001", "lr": "0.000250325", "gnorm": "2.156", "clip": "0.000", "oom": "0.000", "wall": "112", "train_wall": "104"}
{"epoch": 1, "update": 0.932, "loss": "6.591", "nll_loss": "5.982", "ppl": "63.2", "wps": "5406", "ups": "10", "wpb": "564.835", "bsz": "15.993", "num_updates": "2001", "lr": "0.0005003", "gnorm": "2.090", "clip": "0.000", "oom": "0.000", "wall": "211", "train_wall": "196"}
{"epoch": 1, "train_loss": "6.468", "train_nll_loss": "5.836", "train_ppl": "57.13", "train_wps": "5453", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "2147", "train_lr": "0.000536796", "train_gnorm": "2.073", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "225", "train_train_wall": "210"}
{"epoch": 1, "valid_loss": "4.535", "valid_nll_loss": "3.472", "valid_ppl": "11.1", "valid_num_updates": "2147"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 1 @ 2147 updates) (writing took 0.2460014820098877 seconds)
{"epoch": 2, "update": 1.466, "loss": "4.470", "nll_loss": "3.470", "ppl": "11.08", "wps": "5654", "ups": "10", "wpb": "560.421", "bsz": "15.986", "num_updates": "3148", "lr": "0.000787021", "gnorm": "1.780", "clip": "0.000", "oom": "0.000", "wall": "331", "train_wall": "303"}
{"epoch": 2, "update": 1.932, "loss": "4.310", "nll_loss": "3.283", "ppl": "9.73", "wps": "5642", "ups": "10", "wpb": "565.425", "bsz": "15.993", "num_updates": "4148", "lr": "0.000981998", "gnorm": "1.718", "clip": "0.000", "oom": "0.000", "wall": "432", "train_wall": "398"}
{"epoch": 2, "train_loss": "4.289", "train_nll_loss": "3.259", "train_ppl": "9.57", "train_wps": "5656", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "4294", "train_lr": "0.000965159", "train_gnorm": "1.708", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "447", "train_train_wall": "412"}
{"epoch": 2, "valid_loss": "3.698", "valid_nll_loss": "2.454", "valid_ppl": "5.48", "valid_num_updates": "4294", "valid_best_loss": "3.69776"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 2 @ 4294 updates) (writing took 0.30525970458984375 seconds)
{"epoch": 3, "update": 2.466, "loss": "3.777", "nll_loss": "2.669", "ppl": "6.36", "wps": "5590", "ups": "10", "wpb": "564.119", "bsz": "15.986", "num_updates": "5295", "lr": "0.000869155", "gnorm": "1.506", "clip": "0.000", "oom": "0.000", "wall": "555", "train_wall": "507"}
{"epoch": 3, "update": 2.932, "loss": "3.681", "nll_loss": "2.561", "ppl": "5.9", "wps": "5617", "ups": "10", "wpb": "566.214", "bsz": "15.993", "num_updates": "6295", "lr": "0.000797135", "gnorm": "1.455", "clip": "0.000", "oom": "0.000", "wall": "655", "train_wall": "601"}
{"epoch": 3, "train_loss": "3.670", "train_nll_loss": "2.549", "train_ppl": "5.85", "train_wps": "5628", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "6441", "train_lr": "0.000788049", "train_gnorm": "1.449", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "670", "train_train_wall": "615"}
{"epoch": 3, "valid_loss": "3.318", "valid_nll_loss": "2.011", "valid_ppl": "4.03", "valid_num_updates": "6441", "valid_best_loss": "3.31817"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 3 @ 6441 updates) (writing took 0.3722069263458252 seconds)
{"epoch": 4, "update": 3.466, "loss": "3.386", "nll_loss": "2.226", "ppl": "4.68", "wps": "5735", "ups": "10", "wpb": "579.127", "bsz": "15.986", "num_updates": "7442", "lr": "0.000733137", "gnorm": "1.334", "clip": "0.000", "oom": "0.000", "wall": "778", "train_wall": "710"}
{"epoch": 4, "update": 3.932, "loss": "3.333", "nll_loss": "2.167", "ppl": "4.49", "wps": "5639", "ups": "10", "wpb": "571.589", "bsz": "15.993", "num_updates": "8442", "lr": "0.000688347", "gnorm": "1.316", "clip": "0.000", "oom": "0.000", "wall": "880", "train_wall": "806"}
{"epoch": 4, "train_loss": "3.326", "train_nll_loss": "2.159", "train_ppl": "4.47", "train_wps": "5602", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "8588", "train_lr": "0.000682471", "train_gnorm": "1.318", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "895", "train_train_wall": "819"}
{"epoch": 4, "valid_loss": "3.123", "valid_nll_loss": "1.791", "valid_ppl": "3.46", "valid_num_updates": "8588", "valid_best_loss": "3.12255"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 4 @ 8588 updates) (writing took 0.344728946685791 seconds)
{"epoch": 5, "update": 4.466, "loss": "3.171", "nll_loss": "1.985", "ppl": "3.96", "wps": "5630", "ups": "10", "wpb": "569.368", "bsz": "16.000", "num_updates": "9589", "lr": "0.000645867", "gnorm": "1.264", "clip": "0.000", "oom": "0.000", "wall": "1003", "train_wall": "914"}
{"epoch": 5, "update": 4.932, "loss": "3.146", "nll_loss": "1.958", "ppl": "3.88", "wps": "5554", "ups": "10", "wpb": "563.837", "bsz": "15.993", "num_updates": "10589", "lr": "0.000614614", "gnorm": "1.258", "clip": "0.000", "oom": "0.000", "wall": "1105", "train_wall": "1010"}
{"epoch": 5, "train_loss": "3.142", "train_nll_loss": "1.954", "train_ppl": "3.87", "train_wps": "5593", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "10735", "train_lr": "0.00061042", "train_gnorm": "1.255", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1119", "train_train_wall": "1024"}
{"epoch": 5, "valid_loss": "2.984", "valid_nll_loss": "1.621", "valid_ppl": "3.08", "valid_num_updates": "10735", "valid_best_loss": "2.98366"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 5 @ 10735 updates) (writing took 0.34276628494262695 seconds)
{"epoch": 6, "update": 5.466, "loss": "3.024", "nll_loss": "1.820", "ppl": "3.53", "wps": "5531", "ups": "10", "wpb": "558.641", "bsz": "15.986", "num_updates": "11736", "lr": "0.000583808", "gnorm": "1.226", "clip": "0.000", "oom": "0.000", "wall": "1227", "train_wall": "1119"}
{"epoch": 6, "update": 5.932, "loss": "3.016", "nll_loss": "1.812", "ppl": "3.51", "wps": "5628", "ups": "10", "wpb": "568.835", "bsz": "15.993", "num_updates": "12736", "lr": "0.00056042", "gnorm": "1.214", "clip": "0.000", "oom": "0.000", "wall": "1328", "train_wall": "1213"}
{"epoch": 6, "train_loss": "3.014", "train_nll_loss": "1.809", "train_ppl": "3.51", "train_wps": "5615", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "12882", "train_lr": "0.000557235", "train_gnorm": "1.214", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1343", "train_train_wall": "1227"}
{"epoch": 6, "valid_loss": "2.912", "valid_nll_loss": "1.544", "valid_ppl": "2.92", "valid_num_updates": "12882", "valid_best_loss": "2.91164"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 6 @ 12882 updates) (writing took 0.43512678146362305 seconds)
{"epoch": 7, "update": 6.466, "loss": "2.925", "nll_loss": "1.709", "ppl": "3.27", "wps": "5661", "ups": "10", "wpb": "574.266", "bsz": "16.000", "num_updates": "13883", "lr": "0.00053677", "gnorm": "1.181", "clip": "0.000", "oom": "0.000", "wall": "1452", "train_wall": "1322"}
{"epoch": 7, "update": 6.932, "loss": "2.927", "nll_loss": "1.713", "ppl": "3.28", "wps": "5616", "ups": "10", "wpb": "568.710", "bsz": "15.993", "num_updates": "14883", "lr": "0.000518424", "gnorm": "1.181", "clip": "0.000", "oom": "0.000", "wall": "1553", "train_wall": "1417"}
{"epoch": 7, "train_loss": "2.925", "train_nll_loss": "1.711", "train_ppl": "3.27", "train_wps": "5609", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "15029", "train_lr": "0.000515899", "train_gnorm": "1.181", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1567", "train_train_wall": "1431"}
{"epoch": 7, "valid_loss": "2.838", "valid_nll_loss": "1.459", "valid_ppl": "2.75", "valid_num_updates": "15029", "valid_best_loss": "2.83763"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 7 @ 15029 updates) (writing took 0.3809502124786377 seconds)
{"epoch": 8, "update": 7.466, "loss": "2.859", "nll_loss": "1.637", "ppl": "3.11", "wps": "5647", "ups": "10", "wpb": "572.825", "bsz": "15.986", "num_updates": "16030", "lr": "0.000499532", "gnorm": "1.154", "clip": "0.000", "oom": "0.000", "wall": "1676", "train_wall": "1526"}
{"epoch": 8, "update": 7.932, "loss": "2.855", "nll_loss": "1.633", "ppl": "3.1", "wps": "5615", "ups": "10", "wpb": "568.309", "bsz": "15.993", "num_updates": "17030", "lr": "0.000484644", "gnorm": "1.158", "clip": "0.000", "oom": "0.000", "wall": "1777", "train_wall": "1621"}
{"epoch": 8, "train_loss": "2.855", "train_nll_loss": "1.632", "train_ppl": "3.1", "train_wps": "5612", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "17176", "train_lr": "0.00048258", "train_gnorm": "1.158", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1791", "train_train_wall": "1635"}
{"epoch": 8, "valid_loss": "2.808", "valid_nll_loss": "1.418", "valid_ppl": "2.67", "valid_num_updates": "17176", "valid_best_loss": "2.80792"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 8 @ 17176 updates) (writing took 0.3170905113220215 seconds)
{"epoch": 9, "update": 8.466, "loss": "2.798", "nll_loss": "1.569", "ppl": "2.97", "wps": "5734", "ups": "10", "wpb": "574.617", "bsz": "16.000", "num_updates": "18177", "lr": "0.000469104", "gnorm": "1.138", "clip": "0.000", "oom": "0.000", "wall": "1898", "train_wall": "1729"}
{"epoch": 9, "update": 8.932, "loss": "2.801", "nll_loss": "1.572", "ppl": "2.97", "wps": "5693", "ups": "10", "wpb": "569.870", "bsz": "15.993", "num_updates": "19177", "lr": "0.000456709", "gnorm": "1.141", "clip": "0.000", "oom": "0.000", "wall": "1998", "train_wall": "1823"}
{"epoch": 9, "train_loss": "2.799", "train_nll_loss": "1.570", "train_ppl": "2.97", "train_wps": "5670", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "19323", "train_lr": "0.00045498", "train_gnorm": "1.141", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2013", "train_train_wall": "1836"}
{"epoch": 9, "valid_loss": "2.780", "valid_nll_loss": "1.394", "valid_ppl": "2.63", "valid_num_updates": "19323", "valid_best_loss": "2.7801"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 9 @ 19323 updates) (writing took 0.3073134422302246 seconds)
{"epoch": 10, "update": 9.466, "loss": "2.753", "nll_loss": "1.519", "ppl": "2.87", "wps": "5667", "ups": "10", "wpb": "569.101", "bsz": "16.000", "num_updates": "20324", "lr": "0.000443635", "gnorm": "1.133", "clip": "0.000", "oom": "0.000", "wall": "2120", "train_wall": "1930"}
{"epoch": 10, "update": 9.932, "loss": "2.753", "nll_loss": "1.520", "ppl": "2.87", "wps": "5675", "ups": "10", "wpb": "569.656", "bsz": "16.000", "num_updates": "21324", "lr": "0.000433107", "gnorm": "1.132", "clip": "0.000", "oom": "0.000", "wall": "2220", "train_wall": "2025"}
{"epoch": 10, "train_loss": "2.753", "train_nll_loss": "1.519", "train_ppl": "2.87", "train_wps": "5658", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "21470", "train_lr": "0.000431632", "train_gnorm": "1.132", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2235", "train_train_wall": "2038"}
{"epoch": 10, "valid_loss": "2.744", "valid_nll_loss": "1.353", "valid_ppl": "2.55", "valid_num_updates": "21470", "valid_best_loss": "2.7436"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 10 @ 21470 updates) (writing took 0.30765199661254883 seconds)
{"epoch": 11, "update": 10.466, "loss": "2.701", "nll_loss": "1.461", "ppl": "2.75", "wps": "5515", "ups": "10", "wpb": "553.376", "bsz": "15.986", "num_updates": "22471", "lr": "0.000421909", "gnorm": "1.116", "clip": "0.000", "oom": "0.000", "wall": "2342", "train_wall": "2132"}
{"epoch": 11, "update": 10.932, "loss": "2.717", "nll_loss": "1.481", "ppl": "2.79", "wps": "5689", "ups": "10", "wpb": "569.901", "bsz": "15.993", "num_updates": "23471", "lr": "0.000412823", "gnorm": "1.119", "clip": "0.000", "oom": "0.000", "wall": "2442", "train_wall": "2226"}
{"epoch": 11, "train_loss": "2.715", "train_nll_loss": "1.479", "train_ppl": "2.79", "train_wps": "5667", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "23617", "train_lr": "0.000411545", "train_gnorm": "1.120", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2457", "train_train_wall": "2240"}
{"epoch": 11, "valid_loss": "2.720", "valid_nll_loss": "1.329", "valid_ppl": "2.51", "valid_num_updates": "23617", "valid_best_loss": "2.71994"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 11 @ 23617 updates) (writing took 0.34278440475463867 seconds)
{"epoch": 12, "update": 11.466, "loss": "2.676", "nll_loss": "1.434", "ppl": "2.7", "wps": "5779", "ups": "10", "wpb": "577.828", "bsz": "16.000", "num_updates": "24618", "lr": "0.000403091", "gnorm": "1.103", "clip": "0.000", "oom": "0.000", "wall": "2564", "train_wall": "2334"}
{"epoch": 12, "update": 11.932, "loss": "2.677", "nll_loss": "1.436", "ppl": "2.71", "wps": "5687", "ups": "10", "wpb": "567.203", "bsz": "15.993", "num_updates": "25618", "lr": "0.000395146", "gnorm": "1.115", "clip": "0.000", "oom": "0.000", "wall": "2663", "train_wall": "2427"}
{"epoch": 12, "train_loss": "2.679", "train_nll_loss": "1.438", "train_ppl": "2.71", "train_wps": "5692", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "25764", "train_lr": "0.000394025", "train_gnorm": "1.115", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2678", "train_train_wall": "2441"}
{"epoch": 12, "valid_loss": "2.705", "valid_nll_loss": "1.307", "valid_ppl": "2.47", "valid_num_updates": "25764", "valid_best_loss": "2.70498"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 12 @ 25764 updates) (writing took 0.36870670318603516 seconds)
{"epoch": 13, "update": 12.466, "loss": "2.644", "nll_loss": "1.398", "ppl": "2.64", "wps": "5714", "ups": "10", "wpb": "568.865", "bsz": "15.986", "num_updates": "26765", "lr": "0.000386586", "gnorm": "1.103", "clip": "0.000", "oom": "0.000", "wall": "2784", "train_wall": "2534"}
{"epoch": 13, "update": 12.932, "loss": "2.649", "nll_loss": "1.404", "ppl": "2.65", "wps": "5693", "ups": "10", "wpb": "566.928", "bsz": "15.993", "num_updates": "27765", "lr": "0.000379561", "gnorm": "1.107", "clip": "0.000", "oom": "0.000", "wall": "2884", "train_wall": "2628"}
{"epoch": 13, "train_loss": "2.650", "train_nll_loss": "1.406", "train_ppl": "2.65", "train_wps": "5694", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "27911", "train_lr": "0.000378567", "train_gnorm": "1.108", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2898", "train_train_wall": "2641"}
{"epoch": 13, "valid_loss": "2.673", "valid_nll_loss": "1.275", "valid_ppl": "2.42", "valid_num_updates": "27911", "valid_best_loss": "2.67326"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 13 @ 27911 updates) (writing took 0.294893741607666 seconds)
{"epoch": 14, "update": 13.466, "loss": "2.612", "nll_loss": "1.363", "ppl": "2.57", "wps": "5689", "ups": "10", "wpb": "566.256", "bsz": "16.000", "num_updates": "28912", "lr": "0.000371955", "gnorm": "1.102", "clip": "0.000", "oom": "0.000", "wall": "3005", "train_wall": "2735"}
{"epoch": 14, "update": 13.932, "loss": "2.624", "nll_loss": "1.377", "ppl": "2.6", "wps": "5715", "ups": "10", "wpb": "569.595", "bsz": "15.993", "num_updates": "29912", "lr": "0.000365685", "gnorm": "1.105", "clip": "0.000", "oom": "0.000", "wall": "3104", "train_wall": "2828"}
{"epoch": 14, "train_loss": "2.624", "train_nll_loss": "1.377", "train_ppl": "2.6", "train_wps": "5694", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "30058", "train_lr": "0.000364796", "train_gnorm": "1.106", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3119", "train_train_wall": "2842"}
{"epoch": 14, "valid_loss": "2.657", "valid_nll_loss": "1.257", "valid_ppl": "2.39", "valid_num_updates": "30058", "valid_best_loss": "2.65683"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 14 @ 30058 updates) (writing took 0.32236528396606445 seconds)
{"epoch": 15, "update": 14.466, "loss": "2.595", "nll_loss": "1.345", "ppl": "2.54", "wps": "5787", "ups": "10", "wpb": "574.982", "bsz": "15.986", "num_updates": "31059", "lr": "0.000358869", "gnorm": "1.092", "clip": "0.000", "oom": "0.000", "wall": "3225", "train_wall": "2935"}
{"epoch": 15, "update": 14.932, "loss": "2.602", "nll_loss": "1.353", "ppl": "2.55", "wps": "5742", "ups": "10", "wpb": "571.160", "bsz": "15.993", "num_updates": "32059", "lr": "0.000353228", "gnorm": "1.101", "clip": "0.000", "oom": "0.000", "wall": "3325", "train_wall": "3029"}
{"epoch": 15, "train_loss": "2.601", "train_nll_loss": "1.352", "train_ppl": "2.55", "train_wps": "5707", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "32205", "train_lr": "0.000352426", "train_gnorm": "1.103", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3339", "train_train_wall": "3042"}
{"epoch": 15, "valid_loss": "2.657", "valid_nll_loss": "1.254", "valid_ppl": "2.39", "valid_num_updates": "32205", "valid_best_loss": "2.65683"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_last.pt (epoch 15 @ 32205 updates) (writing took 0.19082283973693848 seconds)
{"epoch": 16, "update": 15.466, "loss": "2.565", "nll_loss": "1.311", "ppl": "2.48", "wps": "5538", "ups": "10", "wpb": "551.835", "bsz": "16.000", "num_updates": "33206", "lr": "0.000347074", "gnorm": "1.099", "clip": "0.000", "oom": "0.000", "wall": "3446", "train_wall": "3136"}
{"epoch": 16, "update": 15.932, "loss": "2.580", "nll_loss": "1.329", "ppl": "2.51", "wps": "5678", "ups": "10", "wpb": "566.442", "bsz": "15.993", "num_updates": "34206", "lr": "0.000341963", "gnorm": "1.099", "clip": "0.000", "oom": "0.000", "wall": "3546", "train_wall": "3230"}
{"epoch": 16, "train_loss": "2.581", "train_nll_loss": "1.330", "train_ppl": "2.51", "train_wps": "5692", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "34352", "train_lr": "0.000341235", "train_gnorm": "1.099", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3560", "train_train_wall": "3243"}
{"epoch": 16, "valid_loss": "2.640", "valid_nll_loss": "1.236", "valid_ppl": "2.36", "valid_num_updates": "34352", "valid_best_loss": "2.64012"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 16 @ 34352 updates) (writing took 0.2984945774078369 seconds)
{"epoch": 17, "update": 16.466, "loss": "2.560", "nll_loss": "1.307", "ppl": "2.48", "wps": "5691", "ups": "10", "wpb": "567.820", "bsz": "16.000", "num_updates": "35353", "lr": "0.00033637", "gnorm": "1.088", "clip": "0.000", "oom": "0.000", "wall": "3667", "train_wall": "3337"}
{"epoch": 17, "update": 16.932, "loss": "2.562", "nll_loss": "1.309", "ppl": "2.48", "wps": "5697", "ups": "10", "wpb": "568.294", "bsz": "16.000", "num_updates": "36353", "lr": "0.000331711", "gnorm": "1.095", "clip": "0.000", "oom": "0.000", "wall": "3766", "train_wall": "3430"}
{"epoch": 17, "train_loss": "2.561", "train_nll_loss": "1.308", "train_ppl": "2.48", "train_wps": "5691", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "36499", "train_lr": "0.000331047", "train_gnorm": "1.096", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3781", "train_train_wall": "3444"}
{"epoch": 17, "valid_loss": "2.622", "valid_nll_loss": "1.217", "valid_ppl": "2.32", "valid_num_updates": "36499", "valid_best_loss": "2.62231"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 17 @ 36499 updates) (writing took 0.33055996894836426 seconds)
{"epoch": 18, "update": 17.466, "loss": "2.534", "nll_loss": "1.277", "ppl": "2.42", "wps": "5768", "ups": "10", "wpb": "576.940", "bsz": "15.986", "num_updates": "37500", "lr": "0.000326599", "gnorm": "1.087", "clip": "0.000", "oom": "0.000", "wall": "3887", "train_wall": "3538"}
{"epoch": 18, "update": 17.932, "loss": "2.544", "nll_loss": "1.290", "ppl": "2.44", "wps": "5716", "ups": "10", "wpb": "571.004", "bsz": "15.993", "num_updates": "38500", "lr": "0.000322329", "gnorm": "1.096", "clip": "0.000", "oom": "0.000", "wall": "3987", "train_wall": "3631"}
{"epoch": 18, "train_loss": "2.544", "train_nll_loss": "1.290", "train_ppl": "2.45", "train_wps": "5686", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "38646", "train_lr": "0.00032172", "train_gnorm": "1.097", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "4002", "train_train_wall": "3645"}
{"epoch": 18, "valid_loss": "2.615", "valid_nll_loss": "1.210", "valid_ppl": "2.31", "valid_num_updates": "38646", "valid_best_loss": "2.61514"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 18 @ 38646 updates) (writing took 0.30941104888916016 seconds)
{"epoch": 19, "update": 18.466, "loss": "2.518", "nll_loss": "1.261", "ppl": "2.4", "wps": "6028", "ups": "11", "wpb": "569.644", "bsz": "16.000", "num_updates": "39647", "lr": "0.000317632", "gnorm": "1.086", "clip": "0.000", "oom": "0.000", "wall": "4103", "train_wall": "3733"}
{"epoch": 19, "update": 18.932, "loss": "2.526", "nll_loss": "1.270", "ppl": "2.41", "wps": "6010", "ups": "11", "wpb": "567.123", "bsz": "15.993", "num_updates": "40647", "lr": "0.000313701", "gnorm": "1.095", "clip": "0.000", "oom": "0.000", "wall": "4197", "train_wall": "3822"}
{"epoch": 19, "train_loss": "2.527", "train_nll_loss": "1.272", "train_ppl": "2.41", "train_wps": "6016", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "40793", "train_lr": "0.000313139", "train_gnorm": "1.095", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "4211", "train_train_wall": "3835"}
{"epoch": 19, "valid_loss": "2.604", "valid_nll_loss": "1.200", "valid_ppl": "2.3", "valid_num_updates": "40793", "valid_best_loss": "2.60368"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 19 @ 40793 updates) (writing took 0.29795312881469727 seconds)
{"epoch": 20, "update": 19.466, "loss": "2.500", "nll_loss": "1.241", "ppl": "2.36", "wps": "6091", "ups": "11", "wpb": "574.564", "bsz": "15.986", "num_updates": "41794", "lr": "0.000309366", "gnorm": "1.088", "clip": "0.000", "oom": "0.000", "wall": "4312", "train_wall": "3923"}
{"epoch": 20, "update": 19.932, "loss": "2.512", "nll_loss": "1.255", "ppl": "2.39", "wps": "6022", "ups": "11", "wpb": "567.763", "bsz": "15.993", "num_updates": "42794", "lr": "0.00030573", "gnorm": "1.098", "clip": "0.000", "oom": "0.000", "wall": "4406", "train_wall": "4011"}
{"epoch": 20, "train_loss": "2.513", "train_nll_loss": "1.256", "train_ppl": "2.39", "train_wps": "6020", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "42940", "train_lr": "0.00030521", "train_gnorm": "1.098", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "4420", "train_train_wall": "4024"}
{"epoch": 20, "valid_loss": "2.602", "valid_nll_loss": "1.200", "valid_ppl": "2.3", "valid_num_updates": "42940", "valid_best_loss": "2.60171"}
| saved checkpoint checkpoints/transformer/v3/che/checkpoint_best.pt (epoch 20 @ 42940 updates) (writing took 0.3016836643218994 seconds)
| done training in 4425.2 seconds
Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer_iwslt_de_en', attention_dropout=0.0, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=True, curriculum=0, data='../format_delex/BPE_1_000', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=256, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=256, decoder_layerdrop=0, decoder_layers=3, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=256, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.2, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=256, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=3, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format='json', log_interval=1000, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=20, max_sentences=16, max_sentences_valid=16, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/transformer/v4/che', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='triple', target_lang='lex', task='translation', tensorboard_logdir='checkpoints/transformer/v4/log', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0)
| [triple] dictionary: 1000 types
| [lex] dictionary: 1000 types
| loaded 4313 examples from: ../format_delex/BPE_1_000/valid.triple-lex.triple
| loaded 4313 examples from: ../format_delex/BPE_1_000/valid.triple-lex.lex
| ../format_delex/BPE_1_000 valid triple-lex 4313 examples
TransformerModel(
  (encoder): TransformerEncoder(
    (embed_tokens): Embedding(1000, 256, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 256, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 256, padding_idx=1)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
)
| model transformer_iwslt_de_en, criterion LabelSmoothedCrossEntropyCriterion
| num. model params: 6048256 (num. trained: 6048256)
| training on 1 GPUs
| max tokens per GPU = None and max sentences per GPU = 16
| no existing checkpoint found checkpoints/transformer/v4/che/checkpoint_last.pt
| loading train data for epoch 0
| loaded 34338 examples from: ../format_delex/BPE_1_000/train.triple-lex.triple
| loaded 34338 examples from: ../format_delex/BPE_1_000/train.triple-lex.lex
| ../format_delex/BPE_1_000 train triple-lex 34338 examples
| NOTICE: your device may support faster training with --fp16
{"epoch": 1, "update": 0.466, "loss": "7.642", "nll_loss": "7.219", "ppl": "148.97", "wps": "6095", "ups": "11", "wpb": "577.300", "bsz": "15.986", "num_updates": "1001", "lr": "0.000250325", "gnorm": "2.249", "clip": "0.000", "oom": "0.000", "wall": "96", "train_wall": "89"}
{"epoch": 1, "update": 0.932, "loss": "6.492", "nll_loss": "5.869", "ppl": "58.45", "wps": "5969", "ups": "11", "wpb": "564.835", "bsz": "15.993", "num_updates": "2001", "lr": "0.0005003", "gnorm": "2.157", "clip": "0.000", "oom": "0.000", "wall": "191", "train_wall": "178"}
{"epoch": 1, "train_loss": "6.374", "train_nll_loss": "5.729", "train_ppl": "53.06", "train_wps": "5997", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "2147", "train_lr": "0.000536796", "train_gnorm": "2.136", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "205", "train_train_wall": "191"}
{"epoch": 1, "valid_loss": "4.544", "valid_nll_loss": "3.494", "valid_ppl": "11.26", "valid_num_updates": "2147"}
| saved checkpoint checkpoints/transformer/v4/che/checkpoint_best.pt (epoch 1 @ 2147 updates) (writing took 0.2449791431427002 seconds)
{"epoch": 2, "update": 1.466, "loss": "4.469", "nll_loss": "3.473", "ppl": "11.1", "wps": "5915", "ups": "11", "wpb": "560.421", "bsz": "15.986", "num_updates": "3148", "lr": "0.000787021", "gnorm": "1.748", "clip": "0.000", "oom": "0.000", "wall": "306", "train_wall": "280"}
{"epoch": 2, "update": 1.932, "loss": "4.313", "nll_loss": "3.291", "ppl": "9.79", "wps": "5967", "ups": "11", "wpb": "565.425", "bsz": "15.993", "num_updates": "4148", "lr": "0.000981998", "gnorm": "1.668", "clip": "0.000", "oom": "0.000", "wall": "401", "train_wall": "369"}
{"epoch": 2, "train_loss": "4.293", "train_nll_loss": "3.268", "train_ppl": "9.63", "train_wps": "5990", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "4294", "train_lr": "0.000965159", "train_gnorm": "1.656", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "415", "train_train_wall": "381"}
{"epoch": 2, "valid_loss": "3.737", "valid_nll_loss": "2.516", "valid_ppl": "5.72", "valid_num_updates": "4294", "valid_best_loss": "3.73675"}
| saved checkpoint checkpoints/transformer/v4/che/checkpoint_best.pt (epoch 2 @ 4294 updates) (writing took 0.2834908962249756 seconds)
{"epoch": 3, "update": 2.466, "loss": "3.793", "nll_loss": "2.692", "ppl": "6.46", "wps": "5965", "ups": "11", "wpb": "564.119", "bsz": "15.986", "num_updates": "5295", "lr": "0.000869155", "gnorm": "1.431", "clip": "0.000", "oom": "0.000", "wall": "516", "train_wall": "470"}
{"epoch": 3, "update": 2.932, "loss": "3.696", "nll_loss": "2.582", "ppl": "5.99", "wps": "5990", "ups": "11", "wpb": "566.214", "bsz": "15.993", "num_updates": "6295", "lr": "0.000797135", "gnorm": "1.383", "clip": "0.000", "oom": "0.000", "wall": "610", "train_wall": "559"}
{"epoch": 3, "train_loss": "3.686", "train_nll_loss": "2.570", "train_ppl": "5.94", "train_wps": "6003", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "6441", "train_lr": "0.000788049", "train_gnorm": "1.378", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "624", "train_train_wall": "572"}
{"epoch": 3, "valid_loss": "3.389", "valid_nll_loss": "2.109", "valid_ppl": "4.31", "valid_num_updates": "6441", "valid_best_loss": "3.38878"}
| saved checkpoint checkpoints/transformer/v4/che/checkpoint_best.pt (epoch 3 @ 6441 updates) (writing took 0.28566813468933105 seconds)
{"epoch": 4, "update": 3.466, "loss": "3.404", "nll_loss": "2.250", "ppl": "4.76", "wps": "6128", "ups": "11", "wpb": "579.127", "bsz": "15.986", "num_updates": "7442", "lr": "0.000733137", "gnorm": "1.270", "clip": "0.000", "oom": "0.000", "wall": "725", "train_wall": "660"}
{"epoch": 4, "update": 3.932, "loss": "3.350", "nll_loss": "2.190", "ppl": "4.56", "wps": "6047", "ups": "11", "wpb": "571.589", "bsz": "15.993", "num_updates": "8442", "lr": "0.000688347", "gnorm": "1.254", "clip": "0.000", "oom": "0.000", "wall": "820", "train_wall": "749"}
{"epoch": 4, "train_loss": "3.344", "train_nll_loss": "2.182", "train_ppl": "4.54", "train_wps": "6004", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "8588", "train_lr": "0.000682471", "train_gnorm": "1.256", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "833", "train_train_wall": "762"}
{"epoch": 4, "valid_loss": "3.166", "valid_nll_loss": "1.855", "valid_ppl": "3.62", "valid_num_updates": "8588", "valid_best_loss": "3.16633"}
| saved checkpoint checkpoints/transformer/v4/che/checkpoint_best.pt (epoch 4 @ 8588 updates) (writing took 0.28767991065979004 seconds)
{"epoch": 5, "update": 4.466, "loss": "3.186", "nll_loss": "2.005", "ppl": "4.01", "wps": "6015", "ups": "11", "wpb": "569.368", "bsz": "16.000", "num_updates": "9589", "lr": "0.000645867", "gnorm": "1.202", "clip": "0.000", "oom": "0.000", "wall": "935", "train_wall": "851"}
{"epoch": 5, "update": 4.932, "loss": "3.162", "nll_loss": "1.979", "ppl": "3.94", "wps": "5852", "ups": "10", "wpb": "563.837", "bsz": "15.993", "num_updates": "10589", "lr": "0.000614614", "gnorm": "1.198", "clip": "0.000", "oom": "0.000", "wall": "1033", "train_wall": "943"}
{"epoch": 5, "train_loss": "3.160", "train_nll_loss": "1.976", "train_ppl": "3.93", "train_wps": "5862", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "10735", "train_lr": "0.00061042", "train_gnorm": "1.194", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1048", "train_train_wall": "957"}
{"epoch": 5, "valid_loss": "3.017", "valid_nll_loss": "1.673", "valid_ppl": "3.19", "valid_num_updates": "10735", "valid_best_loss": "3.01694"}
| saved checkpoint checkpoints/transformer/v4/che/checkpoint_best.pt (epoch 5 @ 10735 updates) (writing took 0.313281774520874 seconds)
{"epoch": 6, "update": 5.466, "loss": "3.038", "nll_loss": "1.837", "ppl": "3.57", "wps": "5347", "ups": "10", "wpb": "558.641", "bsz": "15.986", "num_updates": "11736", "lr": "0.000583808", "gnorm": "1.155", "clip": "0.000", "oom": "0.000", "wall": "1159", "train_wall": "1055"}
Traceback (most recent call last):
  File "/veu4/usuaris26/smadexAB/anaconda3/bin/fairseq-train", line 8, in <module>
    sys.exit(cli_main())
  File "/veu4/usuaris26/smadexAB/anaconda3/lib/python3.7/site-packages/fairseq_cli/train.py", line 333, in cli_main
    main(args)
  File "/veu4/usuaris26/smadexAB/anaconda3/lib/python3.7/site-packages/fairseq_cli/train.py", line 86, in main
    train(args, trainer, task, epoch_itr)
  File "/veu4/usuaris26/smadexAB/anaconda3/lib/python3.7/site-packages/fairseq_cli/train.py", line 141, in train
    progress.log(stats, tag='train', step=stats['num_updates'])
  File "/veu4/usuaris26/smadexAB/anaconda3/lib/python3.7/site-packages/fairseq/progress_bar.py", line 253, in log
    self._log_to_tensorboard(stats, tag, step)
  File "/veu4/usuaris26/smadexAB/anaconda3/lib/python3.7/site-packages/fairseq/progress_bar.py", line 276, in _log_to_tensorboard
    writer.add_scalar(key, stats[key], step)
  File "/veu4/usuaris26/smadexAB/anaconda3/lib/python3.7/site-packages/tensorboardX/writer.py", line 405, in add_scalar
    scalar(tag, scalar_value), global_step, walltime)
  File "/veu4/usuaris26/smadexAB/anaconda3/lib/python3.7/site-packages/tensorboardX/summary.py", line 146, in scalar
    scalar = make_np(scalar)
  File "/veu4/usuaris26/smadexAB/anaconda3/lib/python3.7/site-packages/tensorboardX/x2num.py", line 26, in make_np
    return check_nan(np.array([x]))
  File "/veu4/usuaris26/smadexAB/anaconda3/lib/python3.7/site-packages/tensorboardX/x2num.py", line 13, in check_nan
    if np.isnan(tmp) or np.isinf(tmp):
  File "/veu4/usuaris26/smadexAB/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 15854) is killed by signal: Killed. 
Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer_iwslt_de_en', attention_dropout=0.0, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../format_delex/BPE_1_000', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=256, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=256, decoder_layerdrop=0, decoder_layers=3, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=256, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.2, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=256, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=3, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format='json', log_interval=1000, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=20, max_sentences=16, max_sentences_valid=16, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/transformer/v5/che', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='triple', target_lang='lex', task='translation', tensorboard_logdir='checkpoints/transformer/v5/log', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0)
| [triple] dictionary: 1000 types
| [lex] dictionary: 1000 types
| loaded 4313 examples from: ../format_delex/BPE_1_000/valid.triple-lex.triple
| loaded 4313 examples from: ../format_delex/BPE_1_000/valid.triple-lex.lex
| ../format_delex/BPE_1_000 valid triple-lex 4313 examples
TransformerModel(
  (encoder): TransformerEncoder(
    (embed_tokens): Embedding(1000, 256, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 256, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 256, padding_idx=1)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
)
| model transformer_iwslt_de_en, criterion LabelSmoothedCrossEntropyCriterion
| num. model params: 6048256 (num. trained: 6048256)
| training on 1 GPUs
| max tokens per GPU = None and max sentences per GPU = 16
| no existing checkpoint found checkpoints/transformer/v5/che/checkpoint_last.pt
| loading train data for epoch 0
| loaded 34338 examples from: ../format_delex/BPE_1_000/train.triple-lex.triple
| loaded 34338 examples from: ../format_delex/BPE_1_000/train.triple-lex.lex
| ../format_delex/BPE_1_000 train triple-lex 34338 examples
| NOTICE: your device may support faster training with --fp16
{"epoch": 1, "update": 0.466, "loss": "7.693", "nll_loss": "7.277", "ppl": "155.1", "wps": "6124", "ups": "11", "wpb": "577.300", "bsz": "15.986", "num_updates": "1001", "lr": "0.000250325", "gnorm": "2.213", "clip": "0.000", "oom": "0.000", "wall": "100", "train_wall": "90"}
{"epoch": 1, "update": 0.932, "loss": "6.520", "nll_loss": "5.901", "ppl": "59.77", "wps": "6007", "ups": "11", "wpb": "564.835", "bsz": "15.993", "num_updates": "2001", "lr": "0.0005003", "gnorm": "2.124", "clip": "0.000", "oom": "0.000", "wall": "193", "train_wall": "178"}
{"epoch": 1, "train_loss": "6.400", "train_nll_loss": "5.759", "train_ppl": "54.17", "train_wps": "6038", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "2147", "train_lr": "0.000536796", "train_gnorm": "2.104", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "207", "train_train_wall": "191"}
{"epoch": 1, "valid_loss": "4.539", "valid_nll_loss": "3.480", "valid_ppl": "11.16", "valid_num_updates": "2147"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 1 @ 2147 updates) (writing took 0.2485661506652832 seconds)
{"epoch": 2, "update": 1.466, "loss": "4.470", "nll_loss": "3.474", "ppl": "11.11", "wps": "5979", "ups": "11", "wpb": "560.421", "bsz": "15.986", "num_updates": "3148", "lr": "0.000787021", "gnorm": "1.770", "clip": "0.000", "oom": "0.000", "wall": "307", "train_wall": "279"}
{"epoch": 2, "update": 1.932, "loss": "4.329", "nll_loss": "3.307", "ppl": "9.9", "wps": "6035", "ups": "11", "wpb": "565.425", "bsz": "15.993", "num_updates": "4148", "lr": "0.000981998", "gnorm": "1.706", "clip": "0.000", "oom": "0.000", "wall": "401", "train_wall": "367"}
{"epoch": 2, "train_loss": "4.311", "train_nll_loss": "3.286", "train_ppl": "9.75", "train_wps": "6058", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "4294", "train_lr": "0.000965159", "train_gnorm": "1.695", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "415", "train_train_wall": "380"}
{"epoch": 2, "valid_loss": "3.794", "valid_nll_loss": "2.567", "valid_ppl": "5.92", "valid_num_updates": "4294", "valid_best_loss": "3.7935"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 2 @ 4294 updates) (writing took 0.2865927219390869 seconds)
{"epoch": 3, "update": 2.466, "loss": "3.833", "nll_loss": "2.736", "ppl": "6.66", "wps": "5983", "ups": "11", "wpb": "564.119", "bsz": "15.986", "num_updates": "5295", "lr": "0.000869155", "gnorm": "1.497", "clip": "0.000", "oom": "0.000", "wall": "515", "train_wall": "468"}
{"epoch": 3, "update": 2.932, "loss": "3.737", "nll_loss": "2.626", "ppl": "6.18", "wps": "6005", "ups": "11", "wpb": "566.214", "bsz": "15.993", "num_updates": "6295", "lr": "0.000797135", "gnorm": "1.446", "clip": "0.000", "oom": "0.000", "wall": "609", "train_wall": "557"}
{"epoch": 3, "train_loss": "3.726", "train_nll_loss": "2.615", "train_ppl": "6.12", "train_wps": "6021", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "6441", "train_lr": "0.000788049", "train_gnorm": "1.440", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "623", "train_train_wall": "570"}
{"epoch": 3, "valid_loss": "3.394", "valid_nll_loss": "2.106", "valid_ppl": "4.31", "valid_num_updates": "6441", "valid_best_loss": "3.39411"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 3 @ 6441 updates) (writing took 0.28888940811157227 seconds)
{"epoch": 4, "update": 3.466, "loss": "3.436", "nll_loss": "2.285", "ppl": "4.87", "wps": "6157", "ups": "11", "wpb": "579.127", "bsz": "15.986", "num_updates": "7442", "lr": "0.000733137", "gnorm": "1.321", "clip": "0.000", "oom": "0.000", "wall": "724", "train_wall": "658"}
{"epoch": 4, "update": 3.932, "loss": "3.381", "nll_loss": "2.223", "ppl": "4.67", "wps": "6074", "ups": "11", "wpb": "571.589", "bsz": "15.993", "num_updates": "8442", "lr": "0.000688347", "gnorm": "1.305", "clip": "0.000", "oom": "0.000", "wall": "818", "train_wall": "746"}
{"epoch": 4, "train_loss": "3.374", "train_nll_loss": "2.215", "train_ppl": "4.64", "train_wps": "6033", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "8588", "train_lr": "0.000682471", "train_gnorm": "1.307", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "832", "train_train_wall": "759"}
{"epoch": 4, "valid_loss": "3.175", "valid_nll_loss": "1.851", "valid_ppl": "3.61", "valid_num_updates": "8588", "valid_best_loss": "3.17504"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 4 @ 8588 updates) (writing took 0.2915005683898926 seconds)
{"epoch": 5, "update": 4.466, "loss": "3.209", "nll_loss": "2.029", "ppl": "4.08", "wps": "6047", "ups": "11", "wpb": "569.368", "bsz": "16.000", "num_updates": "9589", "lr": "0.000645867", "gnorm": "1.250", "clip": "0.000", "oom": "0.000", "wall": "932", "train_wall": "847"}
{"epoch": 5, "update": 4.932, "loss": "3.184", "nll_loss": "2.001", "ppl": "4", "wps": "5987", "ups": "11", "wpb": "563.837", "bsz": "15.993", "num_updates": "10589", "lr": "0.000614614", "gnorm": "1.244", "clip": "0.000", "oom": "0.000", "wall": "1026", "train_wall": "936"}
{"epoch": 5, "train_loss": "3.181", "train_nll_loss": "1.998", "train_ppl": "4", "train_wps": "6025", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "10735", "train_lr": "0.00061042", "train_gnorm": "1.241", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1040", "train_train_wall": "949"}
{"epoch": 5, "valid_loss": "3.027", "valid_nll_loss": "1.675", "valid_ppl": "3.19", "valid_num_updates": "10735", "valid_best_loss": "3.02745"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 5 @ 10735 updates) (writing took 0.3058488368988037 seconds)
{"epoch": 6, "update": 5.466, "loss": "3.057", "nll_loss": "1.857", "ppl": "3.62", "wps": "5923", "ups": "11", "wpb": "558.641", "bsz": "15.986", "num_updates": "11736", "lr": "0.000583808", "gnorm": "1.201", "clip": "0.000", "oom": "0.000", "wall": "1141", "train_wall": "1037"}
{"epoch": 6, "update": 5.932, "loss": "3.049", "nll_loss": "1.849", "ppl": "3.6", "wps": "6033", "ups": "11", "wpb": "568.835", "bsz": "15.993", "num_updates": "12736", "lr": "0.00056042", "gnorm": "1.193", "clip": "0.000", "oom": "0.000", "wall": "1235", "train_wall": "1126"}
{"epoch": 6, "train_loss": "3.047", "train_nll_loss": "1.847", "train_ppl": "3.6", "train_wps": "6018", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "12882", "train_lr": "0.000557235", "train_gnorm": "1.194", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1249", "train_train_wall": "1139"}
{"epoch": 6, "valid_loss": "2.948", "valid_nll_loss": "1.590", "valid_ppl": "3.01", "valid_num_updates": "12882", "valid_best_loss": "2.94793"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 6 @ 12882 updates) (writing took 0.32604098320007324 seconds)
{"epoch": 7, "update": 6.466, "loss": "2.954", "nll_loss": "1.742", "ppl": "3.34", "wps": "6058", "ups": "11", "wpb": "574.266", "bsz": "16.000", "num_updates": "13883", "lr": "0.00053677", "gnorm": "1.169", "clip": "0.000", "oom": "0.000", "wall": "1350", "train_wall": "1227"}
{"epoch": 7, "update": 6.932, "loss": "2.953", "nll_loss": "1.742", "ppl": "3.35", "wps": "5873", "ups": "10", "wpb": "568.710", "bsz": "15.993", "num_updates": "14883", "lr": "0.000518424", "gnorm": "1.168", "clip": "0.000", "oom": "0.000", "wall": "1449", "train_wall": "1320"}
{"epoch": 7, "train_loss": "2.952", "train_nll_loss": "1.740", "train_ppl": "3.34", "train_wps": "5853", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "15029", "train_lr": "0.000515899", "train_gnorm": "1.168", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1463", "train_train_wall": "1334"}
{"epoch": 7, "valid_loss": "2.875", "valid_nll_loss": "1.501", "valid_ppl": "2.83", "valid_num_updates": "15029", "valid_best_loss": "2.87541"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 7 @ 15029 updates) (writing took 0.3131234645843506 seconds)
{"epoch": 8, "update": 7.466, "loss": "2.887", "nll_loss": "1.667", "ppl": "3.18", "wps": "5764", "ups": "10", "wpb": "572.825", "bsz": "15.986", "num_updates": "16030", "lr": "0.000499532", "gnorm": "1.142", "clip": "0.000", "oom": "0.000", "wall": "1569", "train_wall": "1427"}
{"epoch": 8, "update": 7.932, "loss": "2.882", "nll_loss": "1.662", "ppl": "3.17", "wps": "5716", "ups": "10", "wpb": "568.309", "bsz": "15.993", "num_updates": "17030", "lr": "0.000484644", "gnorm": "1.146", "clip": "0.000", "oom": "0.000", "wall": "1669", "train_wall": "1520"}
{"epoch": 8, "train_loss": "2.881", "train_nll_loss": "1.662", "train_ppl": "3.16", "train_wps": "5708", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "17176", "train_lr": "0.00048258", "train_gnorm": "1.146", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1683", "train_train_wall": "1534"}
{"epoch": 8, "valid_loss": "2.842", "valid_nll_loss": "1.458", "valid_ppl": "2.75", "valid_num_updates": "17176", "valid_best_loss": "2.84177"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 8 @ 17176 updates) (writing took 0.3069760799407959 seconds)
{"epoch": 9, "update": 8.466, "loss": "2.820", "nll_loss": "1.592", "ppl": "3.01", "wps": "5772", "ups": "10", "wpb": "574.617", "bsz": "16.000", "num_updates": "18177", "lr": "0.000469104", "gnorm": "1.127", "clip": "0.000", "oom": "0.000", "wall": "1790", "train_wall": "1627"}
{"epoch": 9, "update": 8.932, "loss": "2.824", "nll_loss": "1.597", "ppl": "3.03", "wps": "5731", "ups": "10", "wpb": "569.870", "bsz": "15.993", "num_updates": "19177", "lr": "0.000456709", "gnorm": "1.131", "clip": "0.000", "oom": "0.000", "wall": "1889", "train_wall": "1720"}
{"epoch": 9, "train_loss": "2.822", "train_nll_loss": "1.596", "train_ppl": "3.02", "train_wps": "5706", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "19323", "train_lr": "0.00045498", "train_gnorm": "1.132", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1904", "train_train_wall": "1734"}
{"epoch": 9, "valid_loss": "2.806", "valid_nll_loss": "1.426", "valid_ppl": "2.69", "valid_num_updates": "19323", "valid_best_loss": "2.80631"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 9 @ 19323 updates) (writing took 0.3123350143432617 seconds)
{"epoch": 10, "update": 9.466, "loss": "2.774", "nll_loss": "1.541", "ppl": "2.91", "wps": "5706", "ups": "10", "wpb": "569.101", "bsz": "16.000", "num_updates": "20324", "lr": "0.000443635", "gnorm": "1.120", "clip": "0.000", "oom": "0.000", "wall": "2010", "train_wall": "1827"}
{"epoch": 10, "update": 9.932, "loss": "2.775", "nll_loss": "1.543", "ppl": "2.91", "wps": "5720", "ups": "10", "wpb": "569.656", "bsz": "16.000", "num_updates": "21324", "lr": "0.000433107", "gnorm": "1.121", "clip": "0.000", "oom": "0.000", "wall": "2110", "train_wall": "1921"}
{"epoch": 10, "train_loss": "2.775", "train_nll_loss": "1.543", "train_ppl": "2.91", "train_wps": "5700", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "21470", "train_lr": "0.000431632", "train_gnorm": "1.121", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2124", "train_train_wall": "1934"}
{"epoch": 10, "valid_loss": "2.775", "valid_nll_loss": "1.388", "valid_ppl": "2.62", "valid_num_updates": "21470", "valid_best_loss": "2.77464"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 10 @ 21470 updates) (writing took 0.29567956924438477 seconds)
{"epoch": 11, "update": 10.466, "loss": "2.720", "nll_loss": "1.482", "ppl": "2.79", "wps": "5563", "ups": "10", "wpb": "553.376", "bsz": "15.986", "num_updates": "22471", "lr": "0.000421909", "gnorm": "1.106", "clip": "0.000", "oom": "0.000", "wall": "2230", "train_wall": "2028"}
{"epoch": 11, "update": 10.932, "loss": "2.737", "nll_loss": "1.501", "ppl": "2.83", "wps": "5568", "ups": "10", "wpb": "569.901", "bsz": "15.993", "num_updates": "23471", "lr": "0.000412823", "gnorm": "1.110", "clip": "0.000", "oom": "0.000", "wall": "2336", "train_wall": "2126"}
{"epoch": 11, "train_loss": "2.735", "train_nll_loss": "1.499", "train_ppl": "2.83", "train_wps": "5556", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "23617", "train_lr": "0.000411545", "train_gnorm": "1.111", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2350", "train_train_wall": "2140"}
{"epoch": 11, "valid_loss": "2.749", "valid_nll_loss": "1.359", "valid_ppl": "2.56", "valid_num_updates": "23617", "valid_best_loss": "2.74874"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 11 @ 23617 updates) (writing took 0.3233628273010254 seconds)
{"epoch": 12, "update": 11.466, "loss": "2.694", "nll_loss": "1.453", "ppl": "2.74", "wps": "5791", "ups": "10", "wpb": "577.828", "bsz": "16.000", "num_updates": "24618", "lr": "0.000403091", "gnorm": "1.094", "clip": "0.000", "oom": "0.000", "wall": "2457", "train_wall": "2234"}
{"epoch": 12, "update": 11.932, "loss": "2.696", "nll_loss": "1.455", "ppl": "2.74", "wps": "5695", "ups": "10", "wpb": "567.203", "bsz": "15.993", "num_updates": "25618", "lr": "0.000395146", "gnorm": "1.103", "clip": "0.000", "oom": "0.000", "wall": "2556", "train_wall": "2327"}
{"epoch": 12, "train_loss": "2.697", "train_nll_loss": "1.457", "train_ppl": "2.75", "train_wps": "5699", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "25764", "train_lr": "0.000394025", "train_gnorm": "1.105", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2571", "train_train_wall": "2340"}
{"epoch": 12, "valid_loss": "2.733", "valid_nll_loss": "1.335", "valid_ppl": "2.52", "valid_num_updates": "25764", "valid_best_loss": "2.73292"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 12 @ 25764 updates) (writing took 0.32288193702697754 seconds)
{"epoch": 13, "update": 12.466, "loss": "2.661", "nll_loss": "1.416", "ppl": "2.67", "wps": "5732", "ups": "10", "wpb": "568.865", "bsz": "15.986", "num_updates": "26765", "lr": "0.000386586", "gnorm": "1.092", "clip": "0.000", "oom": "0.000", "wall": "2677", "train_wall": "2433"}
{"epoch": 13, "update": 12.932, "loss": "2.666", "nll_loss": "1.423", "ppl": "2.68", "wps": "5711", "ups": "10", "wpb": "566.928", "bsz": "15.993", "num_updates": "27765", "lr": "0.000379561", "gnorm": "1.096", "clip": "0.000", "oom": "0.000", "wall": "2776", "train_wall": "2527"}
{"epoch": 13, "train_loss": "2.668", "train_nll_loss": "1.426", "train_ppl": "2.69", "train_wps": "5717", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "27911", "train_lr": "0.000378567", "train_gnorm": "1.098", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2790", "train_train_wall": "2540"}
{"epoch": 13, "valid_loss": "2.695", "valid_nll_loss": "1.299", "valid_ppl": "2.46", "valid_num_updates": "27911", "valid_best_loss": "2.69531"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 13 @ 27911 updates) (writing took 0.29871463775634766 seconds)
{"epoch": 14, "update": 13.466, "loss": "2.630", "nll_loss": "1.382", "ppl": "2.61", "wps": "5681", "ups": "10", "wpb": "566.256", "bsz": "16.000", "num_updates": "28912", "lr": "0.000371955", "gnorm": "1.088", "clip": "0.000", "oom": "0.000", "wall": "2897", "train_wall": "2634"}
{"epoch": 14, "update": 13.932, "loss": "2.642", "nll_loss": "1.396", "ppl": "2.63", "wps": "5710", "ups": "10", "wpb": "569.595", "bsz": "15.993", "num_updates": "29912", "lr": "0.000365685", "gnorm": "1.096", "clip": "0.000", "oom": "0.000", "wall": "2997", "train_wall": "2727"}
{"epoch": 14, "train_loss": "2.642", "train_nll_loss": "1.396", "train_ppl": "2.63", "train_wps": "5690", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "30058", "train_lr": "0.000364796", "train_gnorm": "1.096", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3011", "train_train_wall": "2741"}
{"epoch": 14, "valid_loss": "2.678", "valid_nll_loss": "1.276", "valid_ppl": "2.42", "valid_num_updates": "30058", "valid_best_loss": "2.67828"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 14 @ 30058 updates) (writing took 0.30669283866882324 seconds)
{"epoch": 15, "update": 14.466, "loss": "2.611", "nll_loss": "1.362", "ppl": "2.57", "wps": "5779", "ups": "10", "wpb": "574.982", "bsz": "15.986", "num_updates": "31059", "lr": "0.000358869", "gnorm": "1.082", "clip": "0.000", "oom": "0.000", "wall": "3118", "train_wall": "2834"}
{"epoch": 15, "update": 14.932, "loss": "2.618", "nll_loss": "1.370", "ppl": "2.58", "wps": "5741", "ups": "10", "wpb": "571.160", "bsz": "15.993", "num_updates": "32059", "lr": "0.000353228", "gnorm": "1.093", "clip": "0.000", "oom": "0.000", "wall": "3217", "train_wall": "2927"}
{"epoch": 15, "train_loss": "2.618", "train_nll_loss": "1.370", "train_ppl": "2.58", "train_wps": "5705", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "32205", "train_lr": "0.000352426", "train_gnorm": "1.095", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3232", "train_train_wall": "2941"}
{"epoch": 15, "valid_loss": "2.680", "valid_nll_loss": "1.277", "valid_ppl": "2.42", "valid_num_updates": "32205", "valid_best_loss": "2.67828"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_last.pt (epoch 15 @ 32205 updates) (writing took 0.16830992698669434 seconds)
{"epoch": 16, "update": 15.466, "loss": "2.581", "nll_loss": "1.328", "ppl": "2.51", "wps": "5555", "ups": "10", "wpb": "551.835", "bsz": "16.000", "num_updates": "33206", "lr": "0.000347074", "gnorm": "1.093", "clip": "0.000", "oom": "0.000", "wall": "3337", "train_wall": "3034"}
{"epoch": 16, "update": 15.932, "loss": "2.596", "nll_loss": "1.346", "ppl": "2.54", "wps": "5698", "ups": "10", "wpb": "566.442", "bsz": "15.993", "num_updates": "34206", "lr": "0.000341963", "gnorm": "1.092", "clip": "0.000", "oom": "0.000", "wall": "3437", "train_wall": "3128"}
{"epoch": 16, "train_loss": "2.597", "train_nll_loss": "1.347", "train_ppl": "2.54", "train_wps": "5709", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "34352", "train_lr": "0.000341235", "train_gnorm": "1.092", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3451", "train_train_wall": "3141"}
{"epoch": 16, "valid_loss": "2.657", "valid_nll_loss": "1.251", "valid_ppl": "2.38", "valid_num_updates": "34352", "valid_best_loss": "2.65736"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 16 @ 34352 updates) (writing took 0.3034372329711914 seconds)
{"epoch": 17, "update": 16.466, "loss": "2.576", "nll_loss": "1.323", "ppl": "2.5", "wps": "5708", "ups": "10", "wpb": "567.820", "bsz": "16.000", "num_updates": "35353", "lr": "0.00033637", "gnorm": "1.086", "clip": "0.000", "oom": "0.000", "wall": "3558", "train_wall": "3235"}
{"epoch": 17, "update": 16.932, "loss": "2.578", "nll_loss": "1.326", "ppl": "2.51", "wps": "5714", "ups": "10", "wpb": "568.294", "bsz": "16.000", "num_updates": "36353", "lr": "0.000331711", "gnorm": "1.091", "clip": "0.000", "oom": "0.000", "wall": "3657", "train_wall": "3328"}
{"epoch": 17, "train_loss": "2.577", "train_nll_loss": "1.325", "train_ppl": "2.51", "train_wps": "5709", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "36499", "train_lr": "0.000331047", "train_gnorm": "1.093", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3672", "train_train_wall": "3341"}
{"epoch": 17, "valid_loss": "2.644", "valid_nll_loss": "1.240", "valid_ppl": "2.36", "valid_num_updates": "36499", "valid_best_loss": "2.64399"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 17 @ 36499 updates) (writing took 0.303056001663208 seconds)
{"epoch": 18, "update": 17.466, "loss": "2.550", "nll_loss": "1.294", "ppl": "2.45", "wps": "5784", "ups": "10", "wpb": "576.940", "bsz": "15.986", "num_updates": "37500", "lr": "0.000326599", "gnorm": "1.071", "clip": "0.000", "oom": "0.000", "wall": "3778", "train_wall": "3435"}
{"epoch": 18, "update": 17.932, "loss": "2.559", "nll_loss": "1.305", "ppl": "2.47", "wps": "5727", "ups": "10", "wpb": "571.004", "bsz": "15.993", "num_updates": "38500", "lr": "0.000322329", "gnorm": "1.084", "clip": "0.000", "oom": "0.000", "wall": "3878", "train_wall": "3528"}
{"epoch": 18, "train_loss": "2.559", "train_nll_loss": "1.305", "train_ppl": "2.47", "train_wps": "5695", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "38646", "train_lr": "0.00032172", "train_gnorm": "1.087", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3892", "train_train_wall": "3542"}
{"epoch": 18, "valid_loss": "2.644", "valid_nll_loss": "1.243", "valid_ppl": "2.37", "valid_num_updates": "38646", "valid_best_loss": "2.64389"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 18 @ 38646 updates) (writing took 0.3090510368347168 seconds)
{"epoch": 19, "update": 18.466, "loss": "2.536", "nll_loss": "1.279", "ppl": "2.43", "wps": "5703", "ups": "10", "wpb": "569.644", "bsz": "16.000", "num_updates": "39647", "lr": "0.000317632", "gnorm": "1.080", "clip": "0.000", "oom": "0.000", "wall": "3999", "train_wall": "3635"}
{"epoch": 19, "update": 18.932, "loss": "2.542", "nll_loss": "1.286", "ppl": "2.44", "wps": "5689", "ups": "10", "wpb": "567.123", "bsz": "15.993", "num_updates": "40647", "lr": "0.000313701", "gnorm": "1.089", "clip": "0.000", "oom": "0.000", "wall": "4098", "train_wall": "3729"}
{"epoch": 19, "train_loss": "2.543", "train_nll_loss": "1.288", "train_ppl": "2.44", "train_wps": "5694", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "40793", "train_lr": "0.000313139", "train_gnorm": "1.088", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "4113", "train_train_wall": "3742"}
{"epoch": 19, "valid_loss": "2.621", "valid_nll_loss": "1.215", "valid_ppl": "2.32", "valid_num_updates": "40793", "valid_best_loss": "2.62127"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 19 @ 40793 updates) (writing took 0.3015627861022949 seconds)
{"epoch": 20, "update": 19.466, "loss": "2.515", "nll_loss": "1.255", "ppl": "2.39", "wps": "5736", "ups": "10", "wpb": "574.564", "bsz": "15.986", "num_updates": "41794", "lr": "0.000309366", "gnorm": "1.080", "clip": "0.000", "oom": "0.000", "wall": "4220", "train_wall": "3836"}
{"epoch": 20, "update": 19.932, "loss": "2.528", "nll_loss": "1.270", "ppl": "2.41", "wps": "5553", "ups": "10", "wpb": "567.763", "bsz": "15.993", "num_updates": "42794", "lr": "0.00030573", "gnorm": "1.090", "clip": "0.000", "oom": "0.000", "wall": "4324", "train_wall": "3934"}
{"epoch": 20, "train_loss": "2.528", "train_nll_loss": "1.271", "train_ppl": "2.41", "train_wps": "5561", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "42940", "train_lr": "0.00030521", "train_gnorm": "1.091", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "4339", "train_train_wall": "3948"}
{"epoch": 20, "valid_loss": "2.614", "valid_nll_loss": "1.208", "valid_ppl": "2.31", "valid_num_updates": "42940", "valid_best_loss": "2.61413"}
| saved checkpoint checkpoints/transformer/v5/che/checkpoint_best.pt (epoch 20 @ 42940 updates) (writing took 0.3082163333892822 seconds)
| done training in 4344.7 seconds
Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer_iwslt_de_en', attention_dropout=0.0, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=True, curriculum=0, data='../format_delex/BPE_1_000', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=256, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=256, decoder_layerdrop=0, decoder_layers=3, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=256, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.2, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=256, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=3, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format='json', log_interval=1000, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=20, max_sentences=16, max_sentences_valid=16, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/transformer/v6/che', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='triple', target_lang='lex', task='translation', tensorboard_logdir='checkpoints/transformer/v6/log', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0)
| [triple] dictionary: 1000 types
| [lex] dictionary: 1000 types
| loaded 4313 examples from: ../format_delex/BPE_1_000/valid.triple-lex.triple
| loaded 4313 examples from: ../format_delex/BPE_1_000/valid.triple-lex.lex
| ../format_delex/BPE_1_000 valid triple-lex 4313 examples
TransformerModel(
  (encoder): TransformerEncoder(
    (embed_tokens): Embedding(1000, 256, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 256, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
)
| model transformer_iwslt_de_en, criterion LabelSmoothedCrossEntropyCriterion
| num. model params: 5785600 (num. trained: 5785600)
| training on 1 GPUs
| max tokens per GPU = None and max sentences per GPU = 16
| no existing checkpoint found checkpoints/transformer/v6/che/checkpoint_last.pt
| loading train data for epoch 0
| loaded 34338 examples from: ../format_delex/BPE_1_000/train.triple-lex.triple
| loaded 34338 examples from: ../format_delex/BPE_1_000/train.triple-lex.lex
| ../format_delex/BPE_1_000 train triple-lex 34338 examples
| NOTICE: your device may support faster training with --fp16
{"epoch": 1, "update": 0.466, "loss": "7.737", "nll_loss": "7.327", "ppl": "160.58", "wps": "5524", "ups": "10", "wpb": "577.300", "bsz": "15.986", "num_updates": "1001", "lr": "0.000250325", "gnorm": "2.272", "clip": "0.000", "oom": "0.000", "wall": "106", "train_wall": "99"}
{"epoch": 1, "update": 0.932, "loss": "6.588", "nll_loss": "5.978", "ppl": "63.05", "wps": "5453", "ups": "10", "wpb": "564.835", "bsz": "15.993", "num_updates": "2001", "lr": "0.0005003", "gnorm": "2.169", "clip": "0.000", "oom": "0.000", "wall": "209", "train_wall": "195"}
{"epoch": 1, "train_loss": "6.468", "train_nll_loss": "5.836", "train_ppl": "57.13", "train_wps": "5492", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "2147", "train_lr": "0.000536796", "train_gnorm": "2.145", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "223", "train_train_wall": "209"}
{"epoch": 1, "valid_loss": "4.617", "valid_nll_loss": "3.578", "valid_ppl": "11.94", "valid_num_updates": "2147"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 1 @ 2147 updates) (writing took 0.23835444450378418 seconds)
{"epoch": 2, "update": 1.466, "loss": "4.499", "nll_loss": "3.506", "ppl": "11.36", "wps": "5552", "ups": "10", "wpb": "560.421", "bsz": "15.986", "num_updates": "3148", "lr": "0.000787021", "gnorm": "1.742", "clip": "0.000", "oom": "0.000", "wall": "332", "train_wall": "304"}
{"epoch": 2, "update": 1.932, "loss": "4.326", "nll_loss": "3.304", "ppl": "9.88", "wps": "5598", "ups": "10", "wpb": "565.425", "bsz": "15.993", "num_updates": "4148", "lr": "0.000981998", "gnorm": "1.655", "clip": "0.000", "oom": "0.000", "wall": "433", "train_wall": "399"}
{"epoch": 2, "train_loss": "4.304", "train_nll_loss": "3.279", "train_ppl": "9.7", "train_wps": "5619", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "4294", "train_lr": "0.000965159", "train_gnorm": "1.643", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "447", "train_train_wall": "412"}
{"epoch": 2, "valid_loss": "3.714", "valid_nll_loss": "2.492", "valid_ppl": "5.63", "valid_num_updates": "4294", "valid_best_loss": "3.71388"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 2 @ 4294 updates) (writing took 0.27980995178222656 seconds)
{"epoch": 3, "update": 2.466, "loss": "3.766", "nll_loss": "2.660", "ppl": "6.32", "wps": "5592", "ups": "10", "wpb": "564.119", "bsz": "15.986", "num_updates": "5295", "lr": "0.000869155", "gnorm": "1.413", "clip": "0.000", "oom": "0.000", "wall": "555", "train_wall": "507"}
{"epoch": 3, "update": 2.932, "loss": "3.667", "nll_loss": "2.548", "ppl": "5.85", "wps": "5615", "ups": "10", "wpb": "566.214", "bsz": "15.993", "num_updates": "6295", "lr": "0.000797135", "gnorm": "1.365", "clip": "0.000", "oom": "0.000", "wall": "656", "train_wall": "602"}
{"epoch": 3, "train_loss": "3.656", "train_nll_loss": "2.536", "train_ppl": "5.8", "train_wps": "5628", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "6441", "train_lr": "0.000788049", "train_gnorm": "1.359", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "671", "train_train_wall": "616"}
{"epoch": 3, "valid_loss": "3.318", "valid_nll_loss": "2.023", "valid_ppl": "4.06", "valid_num_updates": "6441", "valid_best_loss": "3.3175"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 3 @ 6441 updates) (writing took 0.29502272605895996 seconds)
{"epoch": 4, "update": 3.466, "loss": "3.376", "nll_loss": "2.217", "ppl": "4.65", "wps": "5742", "ups": "10", "wpb": "579.127", "bsz": "15.986", "num_updates": "7442", "lr": "0.000733137", "gnorm": "1.256", "clip": "0.000", "oom": "0.000", "wall": "779", "train_wall": "711"}
{"epoch": 4, "update": 3.932, "loss": "3.320", "nll_loss": "2.155", "ppl": "4.45", "wps": "5662", "ups": "10", "wpb": "571.589", "bsz": "15.993", "num_updates": "8442", "lr": "0.000688347", "gnorm": "1.241", "clip": "0.000", "oom": "0.000", "wall": "880", "train_wall": "805"}
{"epoch": 4, "train_loss": "3.314", "train_nll_loss": "2.148", "train_ppl": "4.43", "train_wps": "5625", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "8588", "train_lr": "0.000682471", "train_gnorm": "1.243", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "894", "train_train_wall": "819"}
{"epoch": 4, "valid_loss": "3.123", "valid_nll_loss": "1.804", "valid_ppl": "3.49", "valid_num_updates": "8588", "valid_best_loss": "3.12252"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 4 @ 8588 updates) (writing took 0.2971975803375244 seconds)
{"epoch": 5, "update": 4.466, "loss": "3.159", "nll_loss": "1.973", "ppl": "3.93", "wps": "5633", "ups": "10", "wpb": "569.368", "bsz": "16.000", "num_updates": "9589", "lr": "0.000645867", "gnorm": "1.193", "clip": "0.000", "oom": "0.000", "wall": "1003", "train_wall": "914"}
{"epoch": 5, "update": 4.932, "loss": "3.137", "nll_loss": "1.949", "ppl": "3.86", "wps": "5575", "ups": "10", "wpb": "563.837", "bsz": "15.993", "num_updates": "10589", "lr": "0.000614614", "gnorm": "1.190", "clip": "0.000", "oom": "0.000", "wall": "1104", "train_wall": "1009"}
{"epoch": 5, "train_loss": "3.134", "train_nll_loss": "1.945", "train_ppl": "3.85", "train_wps": "5592", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "10735", "train_lr": "0.00061042", "train_gnorm": "1.186", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1119", "train_train_wall": "1024"}
{"epoch": 5, "valid_loss": "2.989", "valid_nll_loss": "1.639", "valid_ppl": "3.11", "valid_num_updates": "10735", "valid_best_loss": "2.98909"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 5 @ 10735 updates) (writing took 0.3157155513763428 seconds)
{"epoch": 6, "update": 5.466, "loss": "3.019", "nll_loss": "1.815", "ppl": "3.52", "wps": "5629", "ups": "10", "wpb": "558.641", "bsz": "15.986", "num_updates": "11736", "lr": "0.000583808", "gnorm": "1.154", "clip": "0.000", "oom": "0.000", "wall": "1226", "train_wall": "1117"}
{"epoch": 6, "update": 5.932, "loss": "3.012", "nll_loss": "1.808", "ppl": "3.5", "wps": "5824", "ups": "10", "wpb": "568.835", "bsz": "15.993", "num_updates": "12736", "lr": "0.00056042", "gnorm": "1.148", "clip": "0.000", "oom": "0.000", "wall": "1322", "train_wall": "1208"}
{"epoch": 6, "train_loss": "3.010", "train_nll_loss": "1.806", "train_ppl": "3.5", "train_wps": "5822", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "12882", "train_lr": "0.000557235", "train_gnorm": "1.147", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1336", "train_train_wall": "1221"}
{"epoch": 6, "valid_loss": "2.914", "valid_nll_loss": "1.552", "valid_ppl": "2.93", "valid_num_updates": "12882", "valid_best_loss": "2.91396"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 6 @ 12882 updates) (writing took 0.3042721748352051 seconds)
{"epoch": 7, "update": 6.466, "loss": "2.922", "nll_loss": "1.707", "ppl": "3.26", "wps": "6014", "ups": "10", "wpb": "574.266", "bsz": "16.000", "num_updates": "13883", "lr": "0.00053677", "gnorm": "1.126", "clip": "0.000", "oom": "0.000", "wall": "1438", "train_wall": "1310"}
{"epoch": 7, "update": 6.932, "loss": "2.923", "nll_loss": "1.709", "ppl": "3.27", "wps": "5963", "ups": "10", "wpb": "568.710", "bsz": "15.993", "num_updates": "14883", "lr": "0.000518424", "gnorm": "1.125", "clip": "0.000", "oom": "0.000", "wall": "1533", "train_wall": "1400"}
{"epoch": 7, "train_loss": "2.921", "train_nll_loss": "1.707", "train_ppl": "3.27", "train_wps": "5953", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "15029", "train_lr": "0.000515899", "train_gnorm": "1.125", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1547", "train_train_wall": "1413"}
{"epoch": 7, "valid_loss": "2.851", "valid_nll_loss": "1.479", "valid_ppl": "2.79", "valid_num_updates": "15029", "valid_best_loss": "2.85066"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 7 @ 15029 updates) (writing took 0.31401944160461426 seconds)
{"epoch": 8, "update": 7.466, "loss": "2.857", "nll_loss": "1.634", "ppl": "3.1", "wps": "6015", "ups": "10", "wpb": "572.825", "bsz": "15.986", "num_updates": "16030", "lr": "0.000499532", "gnorm": "1.098", "clip": "0.000", "oom": "0.000", "wall": "1649", "train_wall": "1502"}
{"epoch": 8, "update": 7.932, "loss": "2.853", "nll_loss": "1.630", "ppl": "3.1", "wps": "5972", "ups": "11", "wpb": "568.309", "bsz": "15.993", "num_updates": "17030", "lr": "0.000484644", "gnorm": "1.101", "clip": "0.000", "oom": "0.000", "wall": "1744", "train_wall": "1592"}
{"epoch": 8, "train_loss": "2.852", "train_nll_loss": "1.630", "train_ppl": "3.09", "train_wps": "5965", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "17176", "train_lr": "0.00048258", "train_gnorm": "1.102", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1758", "train_train_wall": "1605"}
{"epoch": 8, "valid_loss": "2.812", "valid_nll_loss": "1.429", "valid_ppl": "2.69", "valid_num_updates": "17176", "valid_best_loss": "2.81153"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 8 @ 17176 updates) (writing took 0.2804439067840576 seconds)
{"epoch": 9, "update": 8.466, "loss": "2.797", "nll_loss": "1.568", "ppl": "2.96", "wps": "6017", "ups": "10", "wpb": "574.617", "bsz": "16.000", "num_updates": "18177", "lr": "0.000469104", "gnorm": "1.086", "clip": "0.000", "oom": "0.000", "wall": "1859", "train_wall": "1694"}
{"epoch": 9, "update": 8.932, "loss": "2.800", "nll_loss": "1.572", "ppl": "2.97", "wps": "5967", "ups": "10", "wpb": "569.870", "bsz": "15.993", "num_updates": "19177", "lr": "0.000456709", "gnorm": "1.089", "clip": "0.000", "oom": "0.000", "wall": "1955", "train_wall": "1784"}
{"epoch": 9, "train_loss": "2.798", "train_nll_loss": "1.570", "train_ppl": "2.97", "train_wps": "5946", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "19323", "train_lr": "0.00045498", "train_gnorm": "1.090", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1969", "train_train_wall": "1797"}
{"epoch": 9, "valid_loss": "2.777", "valid_nll_loss": "1.397", "valid_ppl": "2.63", "valid_num_updates": "19323", "valid_best_loss": "2.77729"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 9 @ 19323 updates) (writing took 0.28208208084106445 seconds)
{"epoch": 10, "update": 9.466, "loss": "2.750", "nll_loss": "1.516", "ppl": "2.86", "wps": "5980", "ups": "11", "wpb": "569.101", "bsz": "16.000", "num_updates": "20324", "lr": "0.000443635", "gnorm": "1.076", "clip": "0.000", "oom": "0.000", "wall": "2070", "train_wall": "1886"}
{"epoch": 10, "update": 9.932, "loss": "2.752", "nll_loss": "1.518", "ppl": "2.86", "wps": "5976", "ups": "10", "wpb": "569.656", "bsz": "16.000", "num_updates": "21324", "lr": "0.000433107", "gnorm": "1.077", "clip": "0.000", "oom": "0.000", "wall": "2166", "train_wall": "1976"}
{"epoch": 10, "train_loss": "2.751", "train_nll_loss": "1.518", "train_ppl": "2.86", "train_wps": "5934", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "21470", "train_lr": "0.000431632", "train_gnorm": "1.077", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2180", "train_train_wall": "1990"}
{"epoch": 10, "valid_loss": "2.749", "valid_nll_loss": "1.361", "valid_ppl": "2.57", "valid_num_updates": "21470", "valid_best_loss": "2.74941"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 10 @ 21470 updates) (writing took 0.2996964454650879 seconds)
{"epoch": 11, "update": 10.466, "loss": "2.700", "nll_loss": "1.460", "ppl": "2.75", "wps": "5746", "ups": "10", "wpb": "553.376", "bsz": "15.986", "num_updates": "22471", "lr": "0.000421909", "gnorm": "1.062", "clip": "0.000", "oom": "0.000", "wall": "2284", "train_wall": "2080"}
{"epoch": 11, "update": 10.932, "loss": "2.716", "nll_loss": "1.479", "ppl": "2.79", "wps": "5943", "ups": "10", "wpb": "569.901", "bsz": "15.993", "num_updates": "23471", "lr": "0.000412823", "gnorm": "1.067", "clip": "0.000", "oom": "0.000", "wall": "2379", "train_wall": "2170"}
{"epoch": 11, "train_loss": "2.714", "train_nll_loss": "1.476", "train_ppl": "2.78", "train_wps": "5914", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "23617", "train_lr": "0.000411545", "train_gnorm": "1.068", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2393", "train_train_wall": "2183"}
{"epoch": 11, "valid_loss": "2.715", "valid_nll_loss": "1.328", "valid_ppl": "2.51", "valid_num_updates": "23617", "valid_best_loss": "2.71544"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 11 @ 23617 updates) (writing took 0.28252530097961426 seconds)
{"epoch": 12, "update": 11.466, "loss": "2.675", "nll_loss": "1.432", "ppl": "2.7", "wps": "6136", "ups": "11", "wpb": "577.828", "bsz": "16.000", "num_updates": "24618", "lr": "0.000403091", "gnorm": "1.053", "clip": "0.000", "oom": "0.000", "wall": "2494", "train_wall": "2272"}
{"epoch": 12, "update": 11.932, "loss": "2.677", "nll_loss": "1.436", "ppl": "2.7", "wps": "5983", "ups": "11", "wpb": "567.203", "bsz": "15.993", "num_updates": "25618", "lr": "0.000395146", "gnorm": "1.063", "clip": "0.000", "oom": "0.000", "wall": "2589", "train_wall": "2361"}
{"epoch": 12, "train_loss": "2.679", "train_nll_loss": "1.437", "train_ppl": "2.71", "train_wps": "5985", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "25764", "train_lr": "0.000394025", "train_gnorm": "1.065", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2603", "train_train_wall": "2374"}
{"epoch": 12, "valid_loss": "2.701", "valid_nll_loss": "1.309", "valid_ppl": "2.48", "valid_num_updates": "25764", "valid_best_loss": "2.7014"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 12 @ 25764 updates) (writing took 0.3027684688568115 seconds)
{"epoch": 13, "update": 12.466, "loss": "2.643", "nll_loss": "1.397", "ppl": "2.63", "wps": "5965", "ups": "10", "wpb": "568.865", "bsz": "15.986", "num_updates": "26765", "lr": "0.000386586", "gnorm": "1.049", "clip": "0.000", "oom": "0.000", "wall": "2705", "train_wall": "2464"}
{"epoch": 13, "update": 12.932, "loss": "2.648", "nll_loss": "1.403", "ppl": "2.64", "wps": "5946", "ups": "10", "wpb": "566.928", "bsz": "15.993", "num_updates": "27765", "lr": "0.000379561", "gnorm": "1.055", "clip": "0.000", "oom": "0.000", "wall": "2800", "train_wall": "2554"}
{"epoch": 13, "train_loss": "2.650", "train_nll_loss": "1.405", "train_ppl": "2.65", "train_wps": "5954", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "27911", "train_lr": "0.000378567", "train_gnorm": "1.057", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2814", "train_train_wall": "2567"}
{"epoch": 13, "valid_loss": "2.678", "valid_nll_loss": "1.281", "valid_ppl": "2.43", "valid_num_updates": "27911", "valid_best_loss": "2.6777"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 13 @ 27911 updates) (writing took 0.2869570255279541 seconds)
{"epoch": 14, "update": 13.466, "loss": "2.614", "nll_loss": "1.365", "ppl": "2.57", "wps": "5925", "ups": "10", "wpb": "566.256", "bsz": "16.000", "num_updates": "28912", "lr": "0.000371955", "gnorm": "1.046", "clip": "0.000", "oom": "0.000", "wall": "2916", "train_wall": "2656"}
{"epoch": 14, "update": 13.932, "loss": "2.625", "nll_loss": "1.377", "ppl": "2.6", "wps": "5961", "ups": "10", "wpb": "569.595", "bsz": "15.993", "num_updates": "29912", "lr": "0.000365685", "gnorm": "1.052", "clip": "0.000", "oom": "0.000", "wall": "3011", "train_wall": "2746"}
{"epoch": 14, "train_loss": "2.625", "train_nll_loss": "1.377", "train_ppl": "2.6", "train_wps": "5943", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "30058", "train_lr": "0.000364796", "train_gnorm": "1.053", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3025", "train_train_wall": "2759"}
{"epoch": 14, "valid_loss": "2.663", "valid_nll_loss": "1.261", "valid_ppl": "2.4", "valid_num_updates": "30058", "valid_best_loss": "2.66272"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 14 @ 30058 updates) (writing took 0.30252814292907715 seconds)
{"epoch": 15, "update": 14.466, "loss": "2.595", "nll_loss": "1.343", "ppl": "2.54", "wps": "6020", "ups": "10", "wpb": "574.982", "bsz": "15.986", "num_updates": "31059", "lr": "0.000358869", "gnorm": "1.034", "clip": "0.000", "oom": "0.000", "wall": "3127", "train_wall": "2849"}
{"epoch": 15, "update": 14.932, "loss": "2.602", "nll_loss": "1.353", "ppl": "2.55", "wps": "5981", "ups": "10", "wpb": "571.160", "bsz": "15.993", "num_updates": "32059", "lr": "0.000353228", "gnorm": "1.046", "clip": "0.000", "oom": "0.000", "wall": "3223", "train_wall": "2938"}
{"epoch": 15, "train_loss": "2.601", "train_nll_loss": "1.352", "train_ppl": "2.55", "train_wps": "5945", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "32205", "train_lr": "0.000352426", "train_gnorm": "1.048", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3237", "train_train_wall": "2951"}
{"epoch": 15, "valid_loss": "2.664", "valid_nll_loss": "1.263", "valid_ppl": "2.4", "valid_num_updates": "32205", "valid_best_loss": "2.66272"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_last.pt (epoch 15 @ 32205 updates) (writing took 0.17180895805358887 seconds)
{"epoch": 16, "update": 15.466, "loss": "2.565", "nll_loss": "1.310", "ppl": "2.48", "wps": "5587", "ups": "10", "wpb": "551.835", "bsz": "16.000", "num_updates": "33206", "lr": "0.000347074", "gnorm": "1.047", "clip": "0.000", "oom": "0.000", "wall": "3341", "train_wall": "3044"}
{"epoch": 16, "update": 15.932, "loss": "2.581", "nll_loss": "1.329", "ppl": "2.51", "wps": "5652", "ups": "10", "wpb": "566.442", "bsz": "15.993", "num_updates": "34206", "lr": "0.000341963", "gnorm": "1.047", "clip": "0.000", "oom": "0.000", "wall": "3443", "train_wall": "3140"}
{"epoch": 16, "train_loss": "2.582", "train_nll_loss": "1.331", "train_ppl": "2.52", "train_wps": "5667", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "34352", "train_lr": "0.000341235", "train_gnorm": "1.048", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3458", "train_train_wall": "3153"}
{"epoch": 16, "valid_loss": "2.639", "valid_nll_loss": "1.234", "valid_ppl": "2.35", "valid_num_updates": "34352", "valid_best_loss": "2.6393"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 16 @ 34352 updates) (writing took 0.3257942199707031 seconds)
{"epoch": 17, "update": 16.466, "loss": "2.561", "nll_loss": "1.307", "ppl": "2.47", "wps": "5934", "ups": "10", "wpb": "567.820", "bsz": "16.000", "num_updates": "35353", "lr": "0.00033637", "gnorm": "1.040", "clip": "0.000", "oom": "0.000", "wall": "3560", "train_wall": "3243"}
{"epoch": 17, "update": 16.932, "loss": "2.562", "nll_loss": "1.308", "ppl": "2.48", "wps": "5933", "ups": "10", "wpb": "568.294", "bsz": "16.000", "num_updates": "36353", "lr": "0.000331711", "gnorm": "1.044", "clip": "0.000", "oom": "0.000", "wall": "3656", "train_wall": "3333"}
{"epoch": 17, "train_loss": "2.561", "train_nll_loss": "1.307", "train_ppl": "2.48", "train_wps": "5902", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "36499", "train_lr": "0.000331047", "train_gnorm": "1.045", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3670", "train_train_wall": "3347"}
{"epoch": 17, "valid_loss": "2.626", "valid_nll_loss": "1.223", "valid_ppl": "2.33", "valid_num_updates": "36499", "valid_best_loss": "2.62647"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 17 @ 36499 updates) (writing took 0.3221557140350342 seconds)
{"epoch": 18, "update": 17.466, "loss": "2.535", "nll_loss": "1.278", "ppl": "2.42", "wps": "5590", "ups": "10", "wpb": "576.940", "bsz": "15.986", "num_updates": "37500", "lr": "0.000326599", "gnorm": "1.031", "clip": "0.000", "oom": "0.000", "wall": "3780", "train_wall": "3444"}
{"epoch": 18, "update": 17.932, "loss": "2.546", "nll_loss": "1.290", "ppl": "2.45", "wps": "5712", "ups": "10", "wpb": "571.004", "bsz": "15.993", "num_updates": "38500", "lr": "0.000322329", "gnorm": "1.040", "clip": "0.000", "oom": "0.000", "wall": "3877", "train_wall": "3535"}
{"epoch": 18, "train_loss": "2.545", "train_nll_loss": "1.290", "train_ppl": "2.45", "train_wps": "5695", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "38646", "train_lr": "0.00032172", "train_gnorm": "1.042", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3891", "train_train_wall": "3548"}
{"epoch": 18, "valid_loss": "2.616", "valid_nll_loss": "1.214", "valid_ppl": "2.32", "valid_num_updates": "38646", "valid_best_loss": "2.61636"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 18 @ 38646 updates) (writing took 0.29944777488708496 seconds)
{"epoch": 19, "update": 18.466, "loss": "2.519", "nll_loss": "1.261", "ppl": "2.4", "wps": "5952", "ups": "10", "wpb": "569.644", "bsz": "16.000", "num_updates": "39647", "lr": "0.000317632", "gnorm": "1.043", "clip": "0.000", "oom": "0.000", "wall": "3993", "train_wall": "3639"}
{"epoch": 19, "update": 18.932, "loss": "2.528", "nll_loss": "1.271", "ppl": "2.41", "wps": "5934", "ups": "10", "wpb": "567.123", "bsz": "15.993", "num_updates": "40647", "lr": "0.000313701", "gnorm": "1.046", "clip": "0.000", "oom": "0.000", "wall": "4089", "train_wall": "3729"}
{"epoch": 19, "train_loss": "2.529", "train_nll_loss": "1.273", "train_ppl": "2.42", "train_wps": "5941", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "40793", "train_lr": "0.000313139", "train_gnorm": "1.046", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "4103", "train_train_wall": "3743"}
{"epoch": 19, "valid_loss": "2.605", "valid_nll_loss": "1.203", "valid_ppl": "2.3", "valid_num_updates": "40793", "valid_best_loss": "2.60484"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 19 @ 40793 updates) (writing took 0.30063652992248535 seconds)
{"epoch": 20, "update": 19.466, "loss": "2.502", "nll_loss": "1.242", "ppl": "2.36", "wps": "6034", "ups": "11", "wpb": "574.564", "bsz": "15.986", "num_updates": "41794", "lr": "0.000309366", "gnorm": "1.033", "clip": "0.000", "oom": "0.000", "wall": "4204", "train_wall": "3833"}
{"epoch": 20, "update": 19.932, "loss": "2.514", "nll_loss": "1.255", "ppl": "2.39", "wps": "5960", "ups": "10", "wpb": "567.763", "bsz": "15.993", "num_updates": "42794", "lr": "0.00030573", "gnorm": "1.043", "clip": "0.000", "oom": "0.000", "wall": "4300", "train_wall": "3923"}
{"epoch": 20, "train_loss": "2.515", "train_nll_loss": "1.257", "train_ppl": "2.39", "train_wps": "5958", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "42940", "train_lr": "0.00030521", "train_gnorm": "1.043", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "4314", "train_train_wall": "3936"}
{"epoch": 20, "valid_loss": "2.601", "valid_nll_loss": "1.199", "valid_ppl": "2.3", "valid_num_updates": "42940", "valid_best_loss": "2.60093"}
| saved checkpoint checkpoints/transformer/v6/che/checkpoint_best.pt (epoch 20 @ 42940 updates) (writing took 0.29617881774902344 seconds)
| done training in 4319.3 seconds
Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer_iwslt_de_en', attention_dropout=0.0, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../format_delex/BPE_1_000', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=256, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=256, decoder_layerdrop=0, decoder_layers=3, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=256, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.2, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=256, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=3, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format='json', log_interval=1000, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=20, max_sentences=16, max_sentences_valid=16, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/transformer/v7/che', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='triple', target_lang='lex', task='translation', tensorboard_logdir='checkpoints/transformer/v7/log', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0)
| [triple] dictionary: 1000 types
| [lex] dictionary: 1000 types
| loaded 4313 examples from: ../format_delex/BPE_1_000/valid.triple-lex.triple
| loaded 4313 examples from: ../format_delex/BPE_1_000/valid.triple-lex.lex
| ../format_delex/BPE_1_000 valid triple-lex 4313 examples
TransformerModel(
  (encoder): TransformerEncoder(
    (embed_tokens): Embedding(1000, 256, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(1000, 256, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
)
| model transformer_iwslt_de_en, criterion LabelSmoothedCrossEntropyCriterion
| num. model params: 5785600 (num. trained: 5785600)
| training on 1 GPUs
| max tokens per GPU = None and max sentences per GPU = 16
| no existing checkpoint found checkpoints/transformer/v7/che/checkpoint_last.pt
| loading train data for epoch 0
| loaded 34338 examples from: ../format_delex/BPE_1_000/train.triple-lex.triple
| loaded 34338 examples from: ../format_delex/BPE_1_000/train.triple-lex.lex
| ../format_delex/BPE_1_000 train triple-lex 34338 examples
| NOTICE: your device may support faster training with --fp16
{"epoch": 1, "update": 0.466, "loss": "7.812", "nll_loss": "7.412", "ppl": "170.35", "wps": "6231", "ups": "11", "wpb": "577.300", "bsz": "15.986", "num_updates": "1001", "lr": "0.000250325", "gnorm": "2.273", "clip": "0.000", "oom": "0.000", "wall": "94", "train_wall": "88"}
{"epoch": 1, "update": 0.932, "loss": "6.640", "nll_loss": "6.038", "ppl": "65.71", "wps": "6074", "ups": "11", "wpb": "564.835", "bsz": "15.993", "num_updates": "2001", "lr": "0.0005003", "gnorm": "2.166", "clip": "0.000", "oom": "0.000", "wall": "187", "train_wall": "176"}
{"epoch": 1, "train_loss": "6.515", "train_nll_loss": "5.890", "train_ppl": "59.31", "train_wps": "6102", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "2147", "train_lr": "0.000536796", "train_gnorm": "2.143", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "201", "train_train_wall": "189"}
{"epoch": 1, "valid_loss": "4.571", "valid_nll_loss": "3.516", "valid_ppl": "11.44", "valid_num_updates": "2147"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 1 @ 2147 updates) (writing took 0.2358546257019043 seconds)
{"epoch": 2, "update": 1.466, "loss": "4.493", "nll_loss": "3.496", "ppl": "11.28", "wps": "6028", "ups": "11", "wpb": "560.421", "bsz": "15.986", "num_updates": "3148", "lr": "0.000787021", "gnorm": "1.783", "clip": "0.000", "oom": "0.000", "wall": "300", "train_wall": "277"}
{"epoch": 2, "update": 1.932, "loss": "4.325", "nll_loss": "3.299", "ppl": "9.84", "wps": "6079", "ups": "11", "wpb": "565.425", "bsz": "15.993", "num_updates": "4148", "lr": "0.000981998", "gnorm": "1.714", "clip": "0.000", "oom": "0.000", "wall": "393", "train_wall": "365"}
{"epoch": 2, "train_loss": "4.303", "train_nll_loss": "3.274", "train_ppl": "9.68", "train_wps": "6103", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "4294", "train_lr": "0.000965159", "train_gnorm": "1.703", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "407", "train_train_wall": "378"}
{"epoch": 2, "valid_loss": "3.709", "valid_nll_loss": "2.465", "valid_ppl": "5.52", "valid_num_updates": "4294", "valid_best_loss": "3.70931"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 2 @ 4294 updates) (writing took 0.2799241542816162 seconds)
{"epoch": 3, "update": 2.466, "loss": "3.776", "nll_loss": "2.668", "ppl": "6.36", "wps": "6063", "ups": "11", "wpb": "564.119", "bsz": "15.986", "num_updates": "5295", "lr": "0.000869155", "gnorm": "1.492", "clip": "0.000", "oom": "0.000", "wall": "506", "train_wall": "466"}
{"epoch": 3, "update": 2.932, "loss": "3.680", "nll_loss": "2.559", "ppl": "5.89", "wps": "6076", "ups": "11", "wpb": "566.214", "bsz": "15.993", "num_updates": "6295", "lr": "0.000797135", "gnorm": "1.444", "clip": "0.000", "oom": "0.000", "wall": "600", "train_wall": "555"}
{"epoch": 3, "train_loss": "3.668", "train_nll_loss": "2.546", "train_ppl": "5.84", "train_wps": "6087", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "6441", "train_lr": "0.000788049", "train_gnorm": "1.437", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "613", "train_train_wall": "568"}
{"epoch": 3, "valid_loss": "3.316", "valid_nll_loss": "2.006", "valid_ppl": "4.02", "valid_num_updates": "6441", "valid_best_loss": "3.31575"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 3 @ 6441 updates) (writing took 0.29369378089904785 seconds)
{"epoch": 4, "update": 3.466, "loss": "3.388", "nll_loss": "2.229", "ppl": "4.69", "wps": "6204", "ups": "11", "wpb": "579.127", "bsz": "15.986", "num_updates": "7442", "lr": "0.000733137", "gnorm": "1.330", "clip": "0.000", "oom": "0.000", "wall": "713", "train_wall": "656"}
{"epoch": 4, "update": 3.932, "loss": "3.334", "nll_loss": "2.169", "ppl": "4.5", "wps": "6101", "ups": "11", "wpb": "571.589", "bsz": "15.993", "num_updates": "8442", "lr": "0.000688347", "gnorm": "1.320", "clip": "0.000", "oom": "0.000", "wall": "807", "train_wall": "745"}
{"epoch": 4, "train_loss": "3.328", "train_nll_loss": "2.161", "train_ppl": "4.47", "train_wps": "6059", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "8588", "train_lr": "0.000682471", "train_gnorm": "1.321", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "821", "train_train_wall": "758"}
{"epoch": 4, "valid_loss": "3.116", "valid_nll_loss": "1.784", "valid_ppl": "3.44", "valid_num_updates": "8588", "valid_best_loss": "3.11618"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 4 @ 8588 updates) (writing took 0.2890787124633789 seconds)
{"epoch": 5, "update": 4.466, "loss": "3.172", "nll_loss": "1.987", "ppl": "3.96", "wps": "6030", "ups": "11", "wpb": "569.368", "bsz": "16.000", "num_updates": "9589", "lr": "0.000645867", "gnorm": "1.260", "clip": "0.000", "oom": "0.000", "wall": "921", "train_wall": "847"}
{"epoch": 5, "update": 4.932, "loss": "3.148", "nll_loss": "1.960", "ppl": "3.89", "wps": "6004", "ups": "11", "wpb": "563.837", "bsz": "15.993", "num_updates": "10589", "lr": "0.000614614", "gnorm": "1.251", "clip": "0.000", "oom": "0.000", "wall": "1015", "train_wall": "935"}
{"epoch": 5, "train_loss": "3.145", "train_nll_loss": "1.957", "train_ppl": "3.88", "train_wps": "6048", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "10735", "train_lr": "0.00061042", "train_gnorm": "1.248", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1028", "train_train_wall": "948"}
{"epoch": 5, "valid_loss": "2.982", "valid_nll_loss": "1.619", "valid_ppl": "3.07", "valid_num_updates": "10735", "valid_best_loss": "2.98162"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 5 @ 10735 updates) (writing took 0.27554821968078613 seconds)
{"epoch": 6, "update": 5.466, "loss": "3.027", "nll_loss": "1.823", "ppl": "3.54", "wps": "5994", "ups": "11", "wpb": "558.641", "bsz": "15.986", "num_updates": "11736", "lr": "0.000583808", "gnorm": "1.214", "clip": "0.000", "oom": "0.000", "wall": "1128", "train_wall": "1037"}
{"epoch": 6, "update": 5.932, "loss": "3.018", "nll_loss": "1.814", "ppl": "3.52", "wps": "6116", "ups": "11", "wpb": "568.835", "bsz": "15.993", "num_updates": "12736", "lr": "0.00056042", "gnorm": "1.206", "clip": "0.000", "oom": "0.000", "wall": "1221", "train_wall": "1124"}
{"epoch": 6, "train_loss": "3.016", "train_nll_loss": "1.812", "train_ppl": "3.51", "train_wps": "6105", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "12882", "train_lr": "0.000557235", "train_gnorm": "1.206", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1234", "train_train_wall": "1137"}
{"epoch": 6, "valid_loss": "2.902", "valid_nll_loss": "1.538", "valid_ppl": "2.9", "valid_num_updates": "12882", "valid_best_loss": "2.90204"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 6 @ 12882 updates) (writing took 0.27980828285217285 seconds)
{"epoch": 7, "update": 6.466, "loss": "2.927", "nll_loss": "1.711", "ppl": "3.27", "wps": "6201", "ups": "11", "wpb": "574.266", "bsz": "16.000", "num_updates": "13883", "lr": "0.00053677", "gnorm": "1.180", "clip": "0.000", "oom": "0.000", "wall": "1333", "train_wall": "1225"}
{"epoch": 7, "update": 6.932, "loss": "2.928", "nll_loss": "1.714", "ppl": "3.28", "wps": "6140", "ups": "11", "wpb": "568.710", "bsz": "15.993", "num_updates": "14883", "lr": "0.000518424", "gnorm": "1.178", "clip": "0.000", "oom": "0.000", "wall": "1425", "train_wall": "1312"}
{"epoch": 7, "train_loss": "2.926", "train_nll_loss": "1.712", "train_ppl": "3.28", "train_wps": "6127", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "15029", "train_lr": "0.000515899", "train_gnorm": "1.179", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1439", "train_train_wall": "1325"}
{"epoch": 7, "valid_loss": "2.843", "valid_nll_loss": "1.461", "valid_ppl": "2.75", "valid_num_updates": "15029", "valid_best_loss": "2.84271"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 7 @ 15029 updates) (writing took 0.2886383533477783 seconds)
{"epoch": 8, "update": 7.466, "loss": "2.860", "nll_loss": "1.637", "ppl": "3.11", "wps": "6187", "ups": "11", "wpb": "572.825", "bsz": "15.986", "num_updates": "16030", "lr": "0.000499532", "gnorm": "1.155", "clip": "0.000", "oom": "0.000", "wall": "1538", "train_wall": "1413"}
{"epoch": 8, "update": 7.932, "loss": "2.857", "nll_loss": "1.634", "ppl": "3.1", "wps": "6114", "ups": "11", "wpb": "568.309", "bsz": "15.993", "num_updates": "17030", "lr": "0.000484644", "gnorm": "1.158", "clip": "0.000", "oom": "0.000", "wall": "1631", "train_wall": "1501"}
{"epoch": 8, "train_loss": "2.856", "train_nll_loss": "1.634", "train_ppl": "3.1", "train_wps": "6107", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "17176", "train_lr": "0.00048258", "train_gnorm": "1.158", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1645", "train_train_wall": "1514"}
{"epoch": 8, "valid_loss": "2.808", "valid_nll_loss": "1.417", "valid_ppl": "2.67", "valid_num_updates": "17176", "valid_best_loss": "2.80754"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 8 @ 17176 updates) (writing took 0.2860419750213623 seconds)
{"epoch": 9, "update": 8.466, "loss": "2.797", "nll_loss": "1.567", "ppl": "2.96", "wps": "6103", "ups": "11", "wpb": "574.617", "bsz": "16.000", "num_updates": "18177", "lr": "0.000469104", "gnorm": "1.139", "clip": "0.000", "oom": "0.000", "wall": "1745", "train_wall": "1603"}
{"epoch": 9, "update": 8.932, "loss": "2.802", "nll_loss": "1.573", "ppl": "2.98", "wps": "6078", "ups": "11", "wpb": "569.870", "bsz": "15.993", "num_updates": "19177", "lr": "0.000456709", "gnorm": "1.144", "clip": "0.000", "oom": "0.000", "wall": "1838", "train_wall": "1691"}
{"epoch": 9, "train_loss": "2.799", "train_nll_loss": "1.571", "train_ppl": "2.97", "train_wps": "6057", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "19323", "train_lr": "0.00045498", "train_gnorm": "1.144", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "1852", "train_train_wall": "1704"}
{"epoch": 9, "valid_loss": "2.778", "valid_nll_loss": "1.393", "valid_ppl": "2.63", "valid_num_updates": "19323", "valid_best_loss": "2.77834"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 9 @ 19323 updates) (writing took 0.28668737411499023 seconds)
{"epoch": 10, "update": 9.466, "loss": "2.752", "nll_loss": "1.518", "ppl": "2.86", "wps": "6136", "ups": "11", "wpb": "569.101", "bsz": "16.000", "num_updates": "20324", "lr": "0.000443635", "gnorm": "1.128", "clip": "0.000", "oom": "0.000", "wall": "1951", "train_wall": "1792"}
{"epoch": 10, "update": 9.932, "loss": "2.754", "nll_loss": "1.521", "ppl": "2.87", "wps": "6129", "ups": "11", "wpb": "569.656", "bsz": "16.000", "num_updates": "21324", "lr": "0.000433107", "gnorm": "1.130", "clip": "0.000", "oom": "0.000", "wall": "2044", "train_wall": "1880"}
{"epoch": 10, "train_loss": "2.753", "train_nll_loss": "1.520", "train_ppl": "2.87", "train_wps": "6106", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "21470", "train_lr": "0.000431632", "train_gnorm": "1.130", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2058", "train_train_wall": "1893"}
{"epoch": 10, "valid_loss": "2.753", "valid_nll_loss": "1.360", "valid_ppl": "2.57", "valid_num_updates": "21470", "valid_best_loss": "2.75283"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 10 @ 21470 updates) (writing took 0.2921788692474365 seconds)
{"epoch": 11, "update": 10.466, "loss": "2.700", "nll_loss": "1.460", "ppl": "2.75", "wps": "5947", "ups": "11", "wpb": "553.376", "bsz": "15.986", "num_updates": "22471", "lr": "0.000421909", "gnorm": "1.116", "clip": "0.000", "oom": "0.000", "wall": "2157", "train_wall": "1981"}
{"epoch": 11, "update": 10.932, "loss": "2.717", "nll_loss": "1.480", "ppl": "2.79", "wps": "6126", "ups": "11", "wpb": "569.901", "bsz": "15.993", "num_updates": "23471", "lr": "0.000412823", "gnorm": "1.122", "clip": "0.000", "oom": "0.000", "wall": "2250", "train_wall": "2069"}
{"epoch": 11, "train_loss": "2.715", "train_nll_loss": "1.478", "train_ppl": "2.78", "train_wps": "6103", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "23617", "train_lr": "0.000411545", "train_gnorm": "1.123", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2264", "train_train_wall": "2082"}
{"epoch": 11, "valid_loss": "2.716", "valid_nll_loss": "1.320", "valid_ppl": "2.5", "valid_num_updates": "23617", "valid_best_loss": "2.71596"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 11 @ 23617 updates) (writing took 0.2962043285369873 seconds)
{"epoch": 12, "update": 11.466, "loss": "2.676", "nll_loss": "1.433", "ppl": "2.7", "wps": "6163", "ups": "11", "wpb": "577.828", "bsz": "16.000", "num_updates": "24618", "lr": "0.000403091", "gnorm": "1.102", "clip": "0.000", "oom": "0.000", "wall": "2364", "train_wall": "2171"}
{"epoch": 12, "update": 11.932, "loss": "2.679", "nll_loss": "1.437", "ppl": "2.71", "wps": "6050", "ups": "11", "wpb": "567.203", "bsz": "15.993", "num_updates": "25618", "lr": "0.000395146", "gnorm": "1.114", "clip": "0.000", "oom": "0.000", "wall": "2457", "train_wall": "2260"}
{"epoch": 12, "train_loss": "2.680", "train_nll_loss": "1.439", "train_ppl": "2.71", "train_wps": "6058", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "25764", "train_lr": "0.000394025", "train_gnorm": "1.115", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2471", "train_train_wall": "2272"}
{"epoch": 12, "valid_loss": "2.699", "valid_nll_loss": "1.296", "valid_ppl": "2.46", "valid_num_updates": "25764", "valid_best_loss": "2.69881"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 12 @ 25764 updates) (writing took 0.28824472427368164 seconds)
{"epoch": 13, "update": 12.466, "loss": "2.644", "nll_loss": "1.398", "ppl": "2.64", "wps": "6062", "ups": "11", "wpb": "568.865", "bsz": "15.986", "num_updates": "26765", "lr": "0.000386586", "gnorm": "1.102", "clip": "0.000", "oom": "0.000", "wall": "2571", "train_wall": "2361"}
{"epoch": 13, "update": 12.932, "loss": "2.650", "nll_loss": "1.405", "ppl": "2.65", "wps": "6055", "ups": "11", "wpb": "566.928", "bsz": "15.993", "num_updates": "27765", "lr": "0.000379561", "gnorm": "1.107", "clip": "0.000", "oom": "0.000", "wall": "2665", "train_wall": "2449"}
{"epoch": 13, "train_loss": "2.652", "train_nll_loss": "1.408", "train_ppl": "2.65", "train_wps": "6061", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "27911", "train_lr": "0.000378567", "train_gnorm": "1.109", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2678", "train_train_wall": "2461"}
{"epoch": 13, "valid_loss": "2.669", "valid_nll_loss": "1.269", "valid_ppl": "2.41", "valid_num_updates": "27911", "valid_best_loss": "2.66929"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 13 @ 27911 updates) (writing took 0.29755735397338867 seconds)
{"epoch": 14, "update": 13.466, "loss": "2.616", "nll_loss": "1.367", "ppl": "2.58", "wps": "6038", "ups": "11", "wpb": "566.256", "bsz": "16.000", "num_updates": "28912", "lr": "0.000371955", "gnorm": "1.102", "clip": "0.000", "oom": "0.000", "wall": "2778", "train_wall": "2550"}
{"epoch": 14, "update": 13.932, "loss": "2.626", "nll_loss": "1.379", "ppl": "2.6", "wps": "6079", "ups": "11", "wpb": "569.595", "bsz": "15.993", "num_updates": "29912", "lr": "0.000365685", "gnorm": "1.107", "clip": "0.000", "oom": "0.000", "wall": "2872", "train_wall": "2637"}
{"epoch": 14, "train_loss": "2.626", "train_nll_loss": "1.380", "train_ppl": "2.6", "train_wps": "6060", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "30058", "train_lr": "0.000364796", "train_gnorm": "1.108", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "2885", "train_train_wall": "2650"}
{"epoch": 14, "valid_loss": "2.655", "valid_nll_loss": "1.250", "valid_ppl": "2.38", "valid_num_updates": "30058", "valid_best_loss": "2.65535"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 14 @ 30058 updates) (writing took 0.31940293312072754 seconds)
{"epoch": 15, "update": 14.466, "loss": "2.596", "nll_loss": "1.345", "ppl": "2.54", "wps": "6133", "ups": "11", "wpb": "574.982", "bsz": "15.986", "num_updates": "31059", "lr": "0.000358869", "gnorm": "1.096", "clip": "0.000", "oom": "0.000", "wall": "2985", "train_wall": "2738"}
{"epoch": 15, "update": 14.932, "loss": "2.603", "nll_loss": "1.354", "ppl": "2.56", "wps": "5974", "ups": "10", "wpb": "571.160", "bsz": "15.993", "num_updates": "32059", "lr": "0.000353228", "gnorm": "1.104", "clip": "0.000", "oom": "0.000", "wall": "3083", "train_wall": "2830"}
{"epoch": 15, "train_loss": "2.603", "train_nll_loss": "1.354", "train_ppl": "2.56", "train_wps": "5923", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "32205", "train_lr": "0.000352426", "train_gnorm": "1.106", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3097", "train_train_wall": "2843"}
{"epoch": 15, "valid_loss": "2.662", "valid_nll_loss": "1.258", "valid_ppl": "2.39", "valid_num_updates": "32205", "valid_best_loss": "2.65535"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_last.pt (epoch 15 @ 32205 updates) (writing took 0.18280887603759766 seconds)
{"epoch": 16, "update": 15.466, "loss": "2.567", "nll_loss": "1.313", "ppl": "2.48", "wps": "5629", "ups": "10", "wpb": "551.835", "bsz": "16.000", "num_updates": "33206", "lr": "0.000347074", "gnorm": "1.101", "clip": "0.000", "oom": "0.000", "wall": "3202", "train_wall": "2935"}
{"epoch": 16, "update": 15.932, "loss": "2.582", "nll_loss": "1.331", "ppl": "2.52", "wps": "5901", "ups": "10", "wpb": "566.442", "bsz": "15.993", "num_updates": "34206", "lr": "0.000341963", "gnorm": "1.099", "clip": "0.000", "oom": "0.000", "wall": "3296", "train_wall": "3024"}
{"epoch": 16, "train_loss": "2.583", "train_nll_loss": "1.332", "train_ppl": "2.52", "train_wps": "5921", "train_ups": "10", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "34352", "train_lr": "0.000341235", "train_gnorm": "1.099", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3310", "train_train_wall": "3037"}
{"epoch": 16, "valid_loss": "2.633", "valid_nll_loss": "1.228", "valid_ppl": "2.34", "valid_num_updates": "34352", "valid_best_loss": "2.63325"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 16 @ 34352 updates) (writing took 0.3012053966522217 seconds)
{"epoch": 17, "update": 16.466, "loss": "2.562", "nll_loss": "1.309", "ppl": "2.48", "wps": "6031", "ups": "11", "wpb": "567.820", "bsz": "16.000", "num_updates": "35353", "lr": "0.00033637", "gnorm": "1.092", "clip": "0.000", "oom": "0.000", "wall": "3410", "train_wall": "3126"}
{"epoch": 17, "update": 16.932, "loss": "2.563", "nll_loss": "1.310", "ppl": "2.48", "wps": "6045", "ups": "11", "wpb": "568.294", "bsz": "16.000", "num_updates": "36353", "lr": "0.000331711", "gnorm": "1.102", "clip": "0.000", "oom": "0.000", "wall": "3504", "train_wall": "3215"}
{"epoch": 17, "train_loss": "2.562", "train_nll_loss": "1.309", "train_ppl": "2.48", "train_wps": "6037", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "36499", "train_lr": "0.000331047", "train_gnorm": "1.103", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3518", "train_train_wall": "3228"}
{"epoch": 17, "valid_loss": "2.620", "valid_nll_loss": "1.213", "valid_ppl": "2.32", "valid_num_updates": "36499", "valid_best_loss": "2.62048"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 17 @ 36499 updates) (writing took 0.29582953453063965 seconds)
{"epoch": 18, "update": 17.466, "loss": "2.535", "nll_loss": "1.278", "ppl": "2.42", "wps": "6134", "ups": "11", "wpb": "576.940", "bsz": "15.986", "num_updates": "37500", "lr": "0.000326599", "gnorm": "1.084", "clip": "0.000", "oom": "0.000", "wall": "3618", "train_wall": "3317"}
{"epoch": 18, "update": 17.932, "loss": "2.545", "nll_loss": "1.290", "ppl": "2.44", "wps": "6086", "ups": "11", "wpb": "571.004", "bsz": "15.993", "num_updates": "38500", "lr": "0.000322329", "gnorm": "1.093", "clip": "0.000", "oom": "0.000", "wall": "3712", "train_wall": "3406"}
{"epoch": 18, "train_loss": "2.545", "train_nll_loss": "1.290", "train_ppl": "2.45", "train_wps": "6053", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "38646", "train_lr": "0.00032172", "train_gnorm": "1.095", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3725", "train_train_wall": "3419"}
{"epoch": 18, "valid_loss": "2.611", "valid_nll_loss": "1.204", "valid_ppl": "2.3", "valid_num_updates": "38646", "valid_best_loss": "2.61068"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 18 @ 38646 updates) (writing took 0.29777979850769043 seconds)
{"epoch": 19, "update": 18.466, "loss": "2.524", "nll_loss": "1.267", "ppl": "2.41", "wps": "6084", "ups": "11", "wpb": "569.644", "bsz": "16.000", "num_updates": "39647", "lr": "0.000317632", "gnorm": "1.092", "clip": "0.000", "oom": "0.000", "wall": "3825", "train_wall": "3507"}
{"epoch": 19, "update": 18.932, "loss": "2.528", "nll_loss": "1.272", "ppl": "2.42", "wps": "6051", "ups": "11", "wpb": "567.123", "bsz": "15.993", "num_updates": "40647", "lr": "0.000313701", "gnorm": "1.099", "clip": "0.000", "oom": "0.000", "wall": "3919", "train_wall": "3596"}
{"epoch": 19, "train_loss": "2.530", "train_nll_loss": "1.274", "train_ppl": "2.42", "train_wps": "6054", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "40793", "train_lr": "0.000313139", "train_gnorm": "1.100", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "3933", "train_train_wall": "3609"}
{"epoch": 19, "valid_loss": "2.600", "valid_nll_loss": "1.193", "valid_ppl": "2.29", "valid_num_updates": "40793", "valid_best_loss": "2.60037"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 19 @ 40793 updates) (writing took 0.29208803176879883 seconds)
{"epoch": 20, "update": 19.466, "loss": "2.502", "nll_loss": "1.242", "ppl": "2.37", "wps": "6117", "ups": "11", "wpb": "574.564", "bsz": "15.986", "num_updates": "41794", "lr": "0.000309366", "gnorm": "1.088", "clip": "0.000", "oom": "0.000", "wall": "4033", "train_wall": "3698"}
{"epoch": 20, "update": 19.932, "loss": "2.514", "nll_loss": "1.257", "ppl": "2.39", "wps": "6050", "ups": "11", "wpb": "567.763", "bsz": "15.993", "num_updates": "42794", "lr": "0.00030573", "gnorm": "1.101", "clip": "0.000", "oom": "0.000", "wall": "4127", "train_wall": "3787"}
{"epoch": 20, "train_loss": "2.515", "train_nll_loss": "1.257", "train_ppl": "2.39", "train_wps": "6048", "train_ups": "11", "train_wpb": "567.658", "train_bsz": "15.993", "train_num_updates": "42940", "train_lr": "0.00030521", "train_gnorm": "1.100", "train_clip": "0.000", "train_oom": "0.000", "train_wall": "4140", "train_train_wall": "3800"}
{"epoch": 20, "valid_loss": "2.596", "valid_nll_loss": "1.192", "valid_ppl": "2.28", "valid_num_updates": "42940", "valid_best_loss": "2.59645"}
| saved checkpoint checkpoints/transformer/v7/che/checkpoint_best.pt (epoch 20 @ 42940 updates) (writing took 0.3044440746307373 seconds)
| done training in 4145.9 seconds
